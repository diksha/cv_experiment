{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0836a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nasha_voxelsafety_com/datasets/rite_hite/v1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4373761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc0665",
   "metadata": {},
   "source": [
    "## Select subset of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "source_dir = '/home/nasha_voxelsafety_com/datasets/dixieline/v1.0/'\n",
    "dest_dir = '/home/nasha_voxelsafety_com/datasets/dixieline/v1.1/'\n",
    "klasses = ['vest', 'no_vest']\n",
    "for klass in klasses:\n",
    "    vest_class = (os.listdir(f'{source_dir}{klass}/'))\n",
    "    print(len(vest_class))\n",
    "    dataset_size = len(vest_class)\n",
    "    selected = np.random.choice(dataset_size, 3500)\n",
    "    selected_filename = list(np.array(vest_class)[list(selected)])\n",
    "\n",
    "    for f in selected_filename:\n",
    "        if not os.path.exists(f\"{dest_dir}{klass}/\"):\n",
    "            os.makedirs(f\"{dest_dir}{klass}/\")\n",
    "        os.system(f\"cp {source_dir}{klass}/{f} {dest_dir}{klass}/{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d421f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b908eb",
   "metadata": {},
   "source": [
    "## Split into Train and Test Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b95f43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nasha_voxelsafety_com/datasets/dixieline/v1.2/'\n",
    "new_dir = '/home/nasha_voxelsafety_com/datasets/dixieline/v1.3/'\n",
    "site_name = 'dixieline'\n",
    "# get the list \n",
    "filenames = []\n",
    "for klass in os.listdir(root_dir):\n",
    "    for f in os.listdir(f\"{root_dir}{klass}\"):\n",
    "        filenames.append((\"-\").join(f.strip(f\"{site_name}-\").strip(\".jpg\").split(\"-\")[:-2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_incidents = np.unique(np.array(filenames))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, test_ids = train_test_split(unique_incidents,test_size=0.2, random_state=42)\n",
    "for klass in os.listdir(root_dir):\n",
    "    for f in os.listdir(f\"{root_dir}{klass}\"):\n",
    "        \n",
    "        \n",
    "        incident_id = (\"-\").join(f.strip(f\"{site_name}-\").strip(\".jpg\").split(\"-\")[:-2])\n",
    "        #train/test split\n",
    "        if incident_id in train_ids:\n",
    "            train_dir =  f\"{new_dir}train/{klass}/\"\n",
    "            if not os.path.exists(train_dir):\n",
    "                os.makedirs(train_dir)\n",
    "            \n",
    "            print(f\"cp {root_dir}{klass}/{f} {train_dir}{f}\") \n",
    "            os.system(f\"cp {root_dir}{klass}/{f} {train_dir}{f}\")\n",
    "        elif incident_id in test_ids:\n",
    "            test_dir = f\"{new_dir}test/{klass}/\"\n",
    "            if not os.path.exists(test_dir):\n",
    "                os.makedirs(test_dir)\n",
    "            print(f\"cp {root_dir}{klass}/{f} {test_dir}{f}\")\n",
    "            os.system(f\"cp {root_dir}{klass}/{f} {test_dir}{f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f652a5",
   "metadata": {},
   "source": [
    "## Split into Train and Test Pytorch Datasets (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb85e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "dataset = datasets.ImageFolder(root_dir,transform=transforms.Compose([transforms.Resize(224),transforms.GaussianBlur(kernel_size=3)]))\n",
    "indices = list(range(0,int(dataset.__len__()),1))\n",
    "np.random.shuffle(indices)\n",
    "split_1 = int(np.floor(0.6 * len(indices)))\n",
    "split_2 = int(np.floor(0.4 * len(indices)))\n",
    "print(split_1,split_1+split_2)\n",
    "train_idx, test_idx, rand_idx = indices[:split_1], indices[split_1:split_1+split_2],indices[split_1+split_2:]\n",
    "train_orig = torch.utils.data.Subset(dataset, train_idx)\n",
    "test_orig = torch.utils.data.Subset(dataset, test_idx)\n",
    "rand_orig = torch.utils.data.Subset(dataset, rand_idx)\n",
    "print(len(indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_names = np.array(dataset.samples)[train_idx,0]\n",
    "test_names = np.array(dataset.samples)[test_idx,0]\n",
    "for im in train_names:\n",
    "    print(im)\n",
    "    im_name = os.path.basename(im)\n",
    "    destination = \"/home/nasha_voxelsafety_com/datasets/rite_hite/v1.1/train\"\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination+\"vest\")\n",
    "        os.makedirs(destination+\"no_vest\")\n",
    "        \n",
    "    klass = \"no_vest\" if \"no_vest\" in im else \"vest\"\n",
    "    os.system(f\"cp {im} {destination}/{klass}/{im_name}\")\n",
    "for im in test_names:\n",
    "    im_name = os.path.basename(im)\n",
    "    destination = \"/home/nasha_voxelsafety_com/datasets/rite_hite/v1.1/test\"\n",
    "    if not os.path.exists(destination):\n",
    "        os.makedirs(destination+\"vest\")\n",
    "        os.makedirs(destination+\"no_vest\")\n",
    "    klass = \"no_vest\" if \"no_vest\" in im else \"vest\"\n",
    "    os.system(f\"cp {im} {destination}/{klass}/{im_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('/home/nasha_voxelsafety_com/datasets/images.txt') as f:\n",
    "    train_names = f.readlines()\n",
    "source = \"/home/nasha_voxelsafety_com/datasets/vestdataset/vest\"\n",
    "destination = \"/home/nasha_voxelsafety_com/datasets/uscold/v1.0/train\"\n",
    "for im in train_names:\n",
    "    if not os.path.exists(destination+\"vest\"):\n",
    "        os.makedirs(destination+\"vest\")\n",
    "    print(f\"cp {source}/{im} {destination}/{im}\")\n",
    "    os.system(f\"cp {source}/{im.strip()} {destination}/vest/{im}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a569f58c",
   "metadata": {},
   "source": [
    "### Training on train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_0 = '/home/nasha_voxelsafety_com/datasets/vest-dataset-clean'\n",
    "root_dir_1 = f\"{new_dir}train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48485117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import ViTFeatureExtractor\n",
    "import os\n",
    "from os import walk\n",
    "import numpy as np\n",
    "class MapDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, map_fn):\n",
    "        self.dataset = dataset\n",
    "        self.map = map_fn\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.map:\n",
    "            x = self.map(self.dataset[index][0])\n",
    "        else:     \n",
    "            x = self.dataset[index][0]  # image\n",
    "        y = self.dataset[index][1]   # label      \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bd4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "def create_datasets(root_dir):\n",
    "    dataset = datasets.ImageFolder(root_dir)\n",
    "    class_names = dataset.classes\n",
    "    idx2class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    class_names = dataset.classes\n",
    "    num_train = len(dataset)\n",
    "    indices = list(range(num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(0.2 * num_train))\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_orig = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_orig = torch.utils.data.Subset(dataset, valid_idx)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k', return_tesnor = \"pt\")\n",
    "    train = MapDataset(train_orig, feature_extractor)\n",
    "    val =  MapDataset(val_orig, feature_extractor)\n",
    "    return dataset, train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458ae19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_class_count(dataset, train, val):\n",
    "    print(dataset.class_to_idx)\n",
    "    idx2class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    class_count =  dict(Counter(dataset.targets))\n",
    "    val_count = dict(Counter(list(np.array(dataset.targets)[val.dataset.indices])))\n",
    "    train_count = dict(Counter(list(np.array(dataset.targets)[train.dataset.indices])))\n",
    "    return class_count, val_count, train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f80886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_weights(dataset,train,train_count):\n",
    "    target_list_train = list(np.array(dataset.targets)[train.dataset.indices])\n",
    "    class_count_train = [i for _,i in sorted(train_count.items())]\n",
    "    class_weights_train = 1./torch.tensor(class_count_train, dtype=torch.float) \n",
    "    class_weights_train_all = class_weights_train[target_list_train]\n",
    "    return class_weights_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "def get_samplers(class_weights_train_all,num_samples_train, num_samples_val):\n",
    "    weighted_sampler_train = WeightedRandomSampler(\n",
    "        weights=class_weights_train_all,\n",
    "        num_samples=num_samples_train,\n",
    "        replacement=True\n",
    "    )\n",
    "    random_sampler_val = RandomSampler(data_source=val,replacement=True,num_samples=num_samples_val)\n",
    "    return weighted_sampler_train, random_sampler_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695715a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(train,val,batch_size,weighted_sampler_train,random_sampler_val):\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train, batch_size=batch_size, num_workers=8, sampler=weighted_sampler_train),\n",
    "        'val': DataLoader(val, batch_size=batch_size, num_workers=8,sampler=random_sampler_val),\n",
    "    }\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b850c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "# site_name = 'laredo-2'\n",
    "num_samples_train=4441 \n",
    "num_samples_val=1110\n",
    "# for i, root_dir in enumerate([root_dir_1,root_dir_0]):\n",
    "for i, root_dir in enumerate([root_dir_1]):\n",
    "    dataset, train, val = create_datasets(root_dir)\n",
    "\n",
    "\n",
    "    class_count, val_count, train_count = get_class_count(dataset,train,val)\n",
    "    print(class_count, val_count, train_count, train.__len__(), val.__len__())\n",
    "\n",
    "    class_weights_train_all = get_train_weights(dataset,train, train_count)\n",
    "\n",
    "    weighted_sampler_train, random_sampler_val = get_samplers(class_weights_train_all,num_samples_train=4441, num_samples_val=1110)\n",
    "    b = (class_weights_train_all) < max((class_weights_train_all))\n",
    "    print(len(b.nonzero()))\n",
    "\n",
    "    batch_size =32\n",
    "    source = site_name if i==0 else \"laredo\"\n",
    "    dataloaders[source] = get_dataloaders(train,val,batch_size,weighted_sampler_train,random_sampler_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f20d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"no_vest\", \"vest\"]\n",
    "import torchvision\n",
    "inputs, classes = next(iter(dataloaders[site_name]['train']))\n",
    "inputs = inputs['pixel_values'][0]\n",
    "print(classes.shape)\n",
    "out = torchvision.utils.make_grid(inputs[0:16])\n",
    "imshow(out, title=[class_names[x] for x in classes[0:16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'google/vit-base-patch16-224-in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15214d70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    num_labels=len(dataset.classes),\n",
    "    id2label={str(i): c for i, c in enumerate(dataset.classes)},\n",
    "    label2id={c: str(i) for i, c in enumerate(dataset.classes)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03690796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import wandb\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def train_model(model, config, dataloaders, dataset_sizes, optimizer):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    model_path = '/home/nasha_voxelsafety_com/voxel/experimental/nasha/ppe/models/'\n",
    "    \n",
    "    wandb.init(project =  \"vit_classification\", entity = \"voxel-wandb\", config = config, tags = [config['tags']])\n",
    "    config = wandb.config\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=0.1)\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())   \n",
    "    best_f1 = 0\n",
    "    model.to(device)\n",
    "    today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, config.num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_tp = 0\n",
    "            running_fp = 0\n",
    "            running_fn = 0\n",
    "            #running_tn = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            \n",
    "#             for (input_0,labels_0), (input_1,labels_1) in zip(dataloaders[\"laredo\"][phase],dataloaders[site_name][phase]):\n",
    "#                 inputs = torch.cat((input_0['pixel_values'][0],input_1['pixel_values'][0]), 0)\n",
    "#                 labels = torch.cat((labels_0,labels_1))\n",
    "            for inputs, labels in dataloaders[site_name][phase]:\n",
    "                inputs = inputs['pixel_values'][0]\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).view(-1)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    outputs = outputs.logits\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                running_tp += torch.sum(np.logical_and(preds.cpu(),labels.data.cpu())).cuda()\n",
    "                running_fp += torch.sum(np.greater(preds.cpu(),labels.data.cpu())).cuda()\n",
    "                running_fn += torch.sum(np.less(preds.cpu(),labels.data.cpu())).cuda()                \n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
    "\n",
    "            epoch_precision = running_tp/(running_tp+running_fp)\n",
    "            epoch_recall = running_tp/(running_tp+running_fn)\n",
    "            epoch_f1 = 2*(epoch_precision*epoch_recall)/(epoch_precision+epoch_recall)\n",
    "            if phase == 'val':\n",
    "                print(\"val loss\", epoch_loss)\n",
    "                print(\"val_f1\", epoch_f1)\n",
    "                wandb.log({\"val loss\":epoch_loss})\n",
    "                wandb.log({\"val_f1\":epoch_f1})\n",
    "            if phase == 'train':\n",
    "                print(\"train loss\", epoch_loss)\n",
    "                wandb.log({\"train loss\":epoch_loss})\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Precision: {:.4f} Recall: {:.4f} F1: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc,epoch_precision,epoch_recall, epoch_f1))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_f1))\n",
    "\n",
    "\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    #save this model\n",
    "\n",
    "    torch.save(model.state_dict(), f'{model_path}/voxel_safetyvest_{config.tags}_{today_date}.pth')\n",
    "    wandb.join()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb7ddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "        'num_epochs': 10,\n",
    "        'learning_rate': 1e-4,\n",
    "        'step':10,\n",
    "        'tags': f\"vit_{site_name}\"\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "train_model(model, config, dataloaders, {\"train\":num_samples_train ,\"val\":num_samples_val}, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c628ac27",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5110c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '/home/nasha_voxelsafety_com/voxel/experimental/nasha/ppe/models/voxel_safetyvest_vit_dixieline_2022-09-16.pth'\n",
    "model.load_state_dict(torch.load(model_name))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8371fdbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copyright 2020-2021 Voxel Labs, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This document may not be reproduced, republished, distributed, transmitted,\n",
    "# displayed, broadcast or otherwise exploited in any manner without the express\n",
    "# prior written permission of Voxel Labs, Inc. The receipt or possession of this\n",
    "# document does not convey any rights to reproduce, disclose, or distribute its\n",
    "# contents, or to manufacture, use, or sell anything that it may describe, in\n",
    "# whole or in part.\n",
    "#\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n",
    "testdir = f\"{new_dir}test\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k', return_tesnor = \"pt\")\n",
    "\n",
    "\n",
    "class TestClassifier:\n",
    "    TEST_TABLE_NAME = \"test_results_images\"\n",
    "    RESULT_TABLE_NAME = \"test_results_metrics\"\n",
    "    PROJECT_NAME = \"ppe_classification_sv_debug\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        labels=[\"no_vest\", \"vest\"],\n",
    "        model_path=\"/home/reza_voxelsafety_com/voxel/experimental/reza/ppe_classification/models/voxel_safety_vest_rite_classifier_attention_resnet_focal_loss_gamma1.5_WS_2022-04-14.pth\",\n",
    "        model_name=\"vit_vest_classifier\",\n",
    "        test_dir=\"/home/reza_voxelsafety_com/experiments/ppe_classifaction/data/scenario_test\",\n",
    "        tags = \"\"\n",
    "    ):\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        self.MODEL_NAME = model_name\n",
    "        self.TEST_DIR = test_dir\n",
    "        self.model = model\n",
    "        self.class_labels = labels\n",
    "        self.results = None\n",
    "        self.test_dataloaders = None\n",
    "        wandb.init(\n",
    "            project=self.PROJECT_NAME,\n",
    "            job_type=\"inference\",\n",
    "            entity=\"voxel-wandb\",\n",
    "            tags = tags,\n",
    "        )\n",
    "\n",
    "    def _input_to_image(self, inp):\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "        return inp\n",
    "\n",
    "    def _calculate_metrics(self, pred, target, threshold=0.5):\n",
    "        pred_flat = np.argmax(pred, 1)\n",
    "\n",
    "        return {\n",
    "            \"metrics\": precision_recall_fscore_support(\n",
    "                y_true=target, y_pred=pred_flat\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def load_dataset(self):\n",
    "\n",
    "        test_datasets = {\n",
    "            x: datasets.ImageFolder(\n",
    "                os.path.join(self.TEST_DIR)\n",
    "            )\n",
    "            for x in [\"test\"]\n",
    "        }\n",
    "        self.names = test_datasets[\"test\"].samples\n",
    "        test_datasets['test'] =  MapDataset(test_datasets['test'], feature_extractor)\n",
    "        self.test_dataloaders = {\n",
    "            x: torch.utils.data.DataLoader(\n",
    "                test_datasets[x], batch_size=1, num_workers=8, shuffle=False\n",
    "            )\n",
    "            for x in [\"test\"]\n",
    "        }\n",
    "\n",
    "    def visualize_predictions(self):\n",
    "        columns = [\"names\", \"Images\", \"Prediction\", \"Ground Truth\"]\n",
    "        for klass in self.class_labels:\n",
    "            columns.append(\"score_\" + klass)\n",
    "        test_dt = wandb.Table(columns=columns)\n",
    "        model_result = []\n",
    "        targets = []\n",
    "        #i, (images, labels) in enumerate(test_loader, 0):\n",
    "        for i, (inputs, labels) in enumerate(self.test_dataloaders[\"test\"], 0):\n",
    "\n",
    "            name = self.names[i][0]\n",
    "            image = Image.open(name)\n",
    "            w, h = image.size\n",
    "            if w * h < 2500:\n",
    "                print(\"small image\")\n",
    "                continue\n",
    "            name_img = name.split('/')[-1]\n",
    "            inputs = inputs['pixel_values'][0]\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            pred = self.model(inputs)\n",
    "            pred = pred.logits\n",
    "            model_result.extend(pred.cpu().detach().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "#             pred = pred.data.cpu().numpy()\n",
    "            guess = self.class_labels[torch.argmax(pred)]\n",
    "\n",
    "            row = [\n",
    "                name_img,\n",
    "                wandb.Image(self._input_to_image(inputs[0].cpu())),\n",
    "                guess,\n",
    "                self.class_labels[labels],\n",
    "            ]\n",
    "\n",
    "            for c_i in pred[0].tolist():\n",
    "                row.append(np.round(c_i, 4))\n",
    "            test_dt.add_data(*row)\n",
    "        self.results = self._calculate_metrics(\n",
    "            np.array(model_result), np.array(targets)\n",
    "        )\n",
    "        wandb.log({self.TEST_TABLE_NAME: test_dt})\n",
    "\n",
    "    def log_metrics(self):\n",
    "        metrics_table = wandb.Table(\n",
    "            columns=[\"Class\", \"Precision\", \"Recall\", \"F1\", \"Support\"]\n",
    "        )\n",
    "\n",
    "        for i in range(len(self.class_labels)):\n",
    "            metrics_table.add_data(\n",
    "                self.class_labels[i],\n",
    "                self.results[\"metrics\"][0][i],\n",
    "                self.results[\"metrics\"][1][i],\n",
    "                self.results[\"metrics\"][2][i],\n",
    "                self.results[\"metrics\"][3][i],\n",
    "            )\n",
    "\n",
    "        wandb.log({self.RESULT_TABLE_NAME: metrics_table})\n",
    "        wandb.join()\n",
    "\n",
    "\n",
    "\n",
    "test_classifier = TestClassifier(test_dir = testdir, model_path=model_name, tags = [\"model:dixieline\",\"data:dixieline_test\"])\n",
    "    # load the dataset\n",
    "test_classifier.load_dataset()\n",
    "    # run model on dataset and upload visuals to wandb\n",
    "test_classifier.visualize_predictions()\n",
    "    # log the overall metrics of the classifier\n",
    "test_classifier.log_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17763296",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdir = \"/home/nasha_voxelsafety_com/datasets/clean_test/uscold_vest\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k', return_tesnor = \"pt\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from PIL import Image\n",
    "TP_n = 0\n",
    "FN_n = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "for klass in os.listdir(testdir):\n",
    "    klasspath = os.path.join(testdir,klass)\n",
    "    filenames = [os.path.join(klasspath, file) for file in os.listdir(klasspath) if not file.startswith('.')]\n",
    "\n",
    "    for filename in filenames:\n",
    "        image = Image.open(filename)\n",
    "        temp = feature_extractor(image, 'pt')\n",
    "        image_tensor = torch.tensor(temp['pixel_values'][0])\n",
    "        image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "        outputs = model(pixel_values=image_tensor)\n",
    "        temp = torch.argmax(outputs.logits)\n",
    "        if klass == \"vest\":\n",
    "            if temp == 1:\n",
    "                TP = TP + 1\n",
    "            elif temp==0:\n",
    "                FN = FN + 1\n",
    "        elif klass == \"no_vest\":\n",
    "            if temp == 0:\n",
    "                TP_n = TP_n + 1\n",
    "            elif temp == 1:\n",
    "                FN_n = FN_n + 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe7ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prec_vest = 100 * (TP/(TP + FN_n ))\n",
    "recall_vest = 100 * (TP/(TP + FN ))\n",
    "prec_novest = 100 * (TP_n/(TP_n + FN ))\n",
    "recal_novest = 100 * (TP_n/(TP_n + FN_n ))\n",
    "f1_vest = 2 * prec_vest * recall_vest / (recall_vest + prec_vest)\n",
    "f1_novest = 2 * prec_novest * recal_novest / (recal_novest + prec_novest)\n",
    "# initialize list of lists\n",
    "data = [['vest', prec_vest, recall_vest, f1_vest], ['no_vest', prec_novest, recal_novest, f1_novest]]\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df = pd.DataFrame(data, columns = ['class', 'prec', 'recall', 'f1'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d64b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    ViTConfig,\n",
    "    ViTFeatureExtractor,\n",
    "    ViTForImageClassification,\n",
    ")\n",
    "device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "configuration = ViTConfig()\n",
    "configuration.num_labels = 2\n",
    "model = ViTForImageClassification(\n",
    "    configuration\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load('/home/reza_voxelsafety_com/voxel/experimental/reza/ppe_classification/models/voxel_safetyvest_vit_2022-04-18.pth')\n",
    ")\n",
    "model = model.to(\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "            project=\"vest_scenario\",\n",
    "            job_type=\"inference\",\n",
    "            entity=\"voxel-wandb\",\n",
    "        )\n",
    "\n",
    "TEST_TABLE_NAME = \"test_results_images\"\n",
    "columns = [\"names\", \"Images\", \"Prediction\"]\n",
    "labels=[\"no_vest\", \"vest\"]\n",
    "for klass in labels:\n",
    "    columns.append(\"score_\" + klass)\n",
    "test_dt = wandb.Table(columns=columns)\n",
    "dir = '/home/reza_voxelsafety_com/voxel/experimental/reza/data'\n",
    "from PIL import Image\n",
    "names = [os.path.join(dir, file) for file in os.listdir(dir) if not file.startswith('.')]\n",
    "for k in range(len(names)):\n",
    "    image = Image.open(names[k])\n",
    "    temp = feature_extractor(image, 'pt')\n",
    "    image_tensor = torch.tensor(temp['pixel_values'][0])\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    outputs = model(pixel_values=image_tensor)\n",
    "    temp = torch.argmax(outputs.logits)\n",
    "    guess = labels[temp.item()]\n",
    "    row = [names[k],\n",
    "            wandb.Image(image),\n",
    "            guess,]\n",
    "    for c_i in outputs.logits.data.cpu().numpy().tolist():\n",
    "        for c in c_i:\n",
    "            row.append(np.round(c, 4))\n",
    "    test_dt.add_data(*row)\n",
    "wandb.log({TEST_TABLE_NAME: test_dt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610d6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
