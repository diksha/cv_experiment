{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data import FloorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import divide_set, input_to_image, plot_imgs_align, masks_to_colorimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_dataset  = FloorDataset(img_dir = '/home/reza_voxelsafety_com/experiments/segmentation/data/floor_segmentation/train/images/', mask_dir = '/home/reza_voxelsafety_com/experiments/segmentation/data/floor_segmentation/train/annotations/', num_class = 2)\n",
    "print(\"Number of images in the dataset {}\".format(len(floor_dataset)))\n",
    "train, val = divide_set(floor_dataset)\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(indices, start, end):\n",
    "    return indices[start : start + end]\n",
    "\n",
    "\n",
    "train_ratio, test_ratio = 0.8, 0.2  # rest will go for test\n",
    "train_count = int(len(floor_dataset) * train_ratio)\n",
    "test_count = int(len(floor_dataset) * train_ratio)\n",
    "\n",
    "indices = torch.randperm(len(floor_dataset))\n",
    "\n",
    "train_indices = get_subset(indices, 0, train_count)\n",
    "test_indices = get_subset(indices, train_count, test_count)\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bas_dir = '/home/reza_voxelsafety_com/experiments/segmentation/data/floor_segmentation'\n",
    "from PIL import Image\n",
    "import os \n",
    "train_names = [floor_dataset._names[i] for i in train_indices.tolist()]\n",
    "test_names = [floor_dataset._names[i] for i in test_indices.tolist()]\n",
    "for name in train_names:\n",
    "    img = Image.open(os.path.join(bas_dir, 'images', name + '.jpg'))\n",
    "    mask = Image.open(os.path.join(bas_dir, 'annotations', name + '.png'))\n",
    "    img.save(os.path.join(bas_dir, 'train' ,'images', name + '.jpg'))\n",
    "    mask.save(os.path.join(bas_dir, 'train' , 'annotations', name + '.png'))\n",
    "for name in test_names:\n",
    "    img = Image.open(os.path.join(bas_dir, 'images', name + '.jpg'))\n",
    "    mask = Image.open(os.path.join(bas_dir, 'annotations', name + '.png'))\n",
    "    img.save(os.path.join(bas_dir, 'test' ,'images', name + '.jpg'))\n",
    "    mask.save(os.path.join(bas_dir, 'test' , 'annotations', name + '.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_dataset  = FloorDataset(img_dir = '/home/reza_voxelsafety_com/experiments/segmentation/data/floor_segmentation/test/images/', mask_dir = '/home/reza_voxelsafety_com/experiments/segmentation/data/floor_segmentation/test/annotations/', num_class = 2)\n",
    "print(\"Number of images in the dataset {}\".format(len(floor_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "}\n",
    "input_img, mask = next(iter(dataloaders['train'])) # getting a batch of the dataset for demonstarion\n",
    "print(input_img.shape)\n",
    "input_images_rgb = [input_to_image(x) for x in input_img.cpu()][:4]  \n",
    "target_masks_rgb = [masks_to_colorimg(x) for x in mask.cpu().numpy()][:4]\n",
    "plot_imgs_align([input_images_rgb, target_masks_rgb], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # setting the device for the process\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import calc_loss\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, data_loaders, scheduler, num_epochs = 25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    model.train() # set the model to train mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        since = time.time()\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])  \n",
    "                model.train()\n",
    "                \n",
    "            else:\n",
    "                model.eval()   \n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            \n",
    "            for inputs, labels in data_loaders[phase]:\n",
    "               \n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs.type(torch.float32))\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            \n",
    "                epoch_samples += inputs.size(0)\n",
    "            \n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "            \n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "        \n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from loss import calc_loss\n",
    "from tqdm import tqdm \n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):    \n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "        \n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))    \n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, data_loaders, scheduler, num_epochs = 25):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    model.train() # set the model to train mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        since = time.time()\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])  \n",
    "                model.train()\n",
    "                \n",
    "            else:\n",
    "                model.eval()   \n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            with tqdm(data_loaders[phase], unit=\"batch\") as tepoch:\n",
    "                for inputs, labels in tepoch:\n",
    "                \n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs.type(torch.float32))\n",
    "                        loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                \n",
    "                    epoch_samples += inputs.size(0)\n",
    "                    tepoch.set_postfix(loss=loss.item())\n",
    "            \n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "            \n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print(\"saving best model\")\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            else:\n",
    "                scheduler.step()\n",
    "            \n",
    "        \n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from torch.optim import lr_scheduler\n",
    "from fastai.vision.learner import create_unet_model\n",
    "# setting up the model structure using smp library (listed in the report)\n",
    "from fastai.vision.models import resnet34\n",
    "model = create_unet_model(resnet34, 2, (320, 480), True, n_in=3)\n",
    "\n",
    "\n",
    "model = model.to(device) # passing the model to the device (cpu/gpu)\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size = 5,\n",
    "                    gamma = 1e-1)\n",
    "\n",
    "model = train_model(model, optimizer_ft, dataloaders, lr_scheduler ,num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './data/floor__best_model.pth' # model parameters save name\n",
    "torch.save(model.state_dict(), save_path) # save model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iou import IoU\n",
    "# import numpy as np\n",
    "# save_path = './data/floor__best_model.pth' # model parameters save name\n",
    "\n",
    "# per_class_mean_accuracy = [] # per class IoU\n",
    "# mean_Accuracy = [] # average IoU\n",
    "# iter = 0\n",
    "# model = smp.Unet(\n",
    "#     encoder_name = \"resnet34\",        \n",
    "#     encoder_weights = 'imagenet',     \n",
    "#     in_channels = 3,                 \n",
    "#     classes = 2,                      \n",
    "# )\n",
    "# model.load_state_dict(torch.load(save_path))\n",
    "model = model.to(device)\n",
    "model.eval()  # model is set for the test process\n",
    "iteration = 0\n",
    "for inputs, labels in dataloaders['test']:\n",
    "    inputs = inputs.to(device) # pasing input to the device\n",
    "    labels = labels.to(device) # passing label to the device\n",
    "    pred = model(inputs.type(torch.float32)) # passing images to the model and predict\n",
    "\n",
    "    pred = pred.data.cpu().numpy()  # bring back the prediction from Gpu to cpu \n",
    "    if iteration % 100 == 0:\n",
    "\n",
    "        input_images_rgb = [input_to_image(x) for x in inputs.cpu()] # input rgb images for visualization\n",
    "        target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()] # mask labels (ground truth) to color image for visualization\n",
    "        pred_rgb = [masks_to_colorimg(x) for x in pred] # convert the prediction to images for visualization\n",
    "        \n",
    "        plot_imgs_align([input_images_rgb, target_masks_rgb, pred_rgb]) # plot images side by side\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    pred_label = [x for x in pred]\n",
    "\n",
    "    pred_label = np.asarray(pred_label)\n",
    "\n",
    "    metric = IoU(num_classes = 2)\n",
    "    metric.add(torch.from_numpy(pred_label), torch.from_numpy(labels)) # calculating IoU based on the library we cited \n",
    "    per_class_IoU, mean_IoU  = metric.value() \n",
    "    per_class_mean_accuracy.append(per_class_IoU) # append the per class IoU\n",
    "\n",
    "    print(\"Current Batch: per class IoU: {} and average IoU {}: \".format(per_class_IoU, mean_IoU)) # print the average and per class IoU for each batch of data\n",
    "    print(\"-----------------------------\")\n",
    "    mean_Accuracy.append(mean_IoU) # append the average Iou\n",
    "    iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.core import DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders.from_dsets(train, val, bs = 8).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n",
    "print(b[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unet_loss:\n",
    "    \"Dice and Focal combined\"\n",
    "    def __init__(self, bce_weight= 0.5, smooth = 0.1):\n",
    "        self._weight = bce_weight\n",
    "        self._smooth = smooth\n",
    "    def _diceloss(self, pred, target):\n",
    "        pred = pred.contiguous()\n",
    "        target = target.contiguous()    \n",
    "\n",
    "        intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "        loss = (1 - ((2. * intersection + self._smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + self._smooth)))\n",
    "        return loss.mean()\n",
    "    def __call__(self, pred, target):\n",
    "        \n",
    "        bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "        pred = torch.sigmoid(pred)\n",
    "        dice = self._diceloss(pred, target)\n",
    "    \n",
    "        loss = bce * self._weight + dice * (1 - self._weight)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "import copy\n",
    "\n",
    "from core.ml.training.dataloaders.registry import get_dataloader\n",
    "from core.ml.training.loss.registry import get_loss\n",
    "from core.ml.training.metrics.registry import get_metrics\n",
    "from core.ml.training.models.registry import get_model_deprecated\n",
    "from core.perception.inference.transforms.registry import get_transforms\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from core.perception.inference.transforms.registry import get_transforms\n",
    "config_path = '/home/reza_voxelsafety_com/voxel/core/ml/training/configs/floor_segment_training.yaml'\n",
    "import yaml\n",
    "with open(config_path, encoding=\"utf-8\") as config_text:\n",
    "        parsed_config = yaml.safe_load(config_text)\n",
    "        import copy\n",
    "learner_init_params = copy.deepcopy(\n",
    "            parsed_config[\"learner\"][\"init_params\"]\n",
    "        )\n",
    "learner_init_params[\"metrics\"] = [\n",
    "            get_metrics(name)\n",
    "            for name in learner_init_params.pop(\"metrics\", [])\n",
    "        ]\n",
    "\n",
    "print(learner_init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learner_init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.models import resnet34\n",
    "model = create_unet_model(resnet34, 2, (480, 320), True, n_in=3)\n",
    "model.to(device)\n",
    "model.train()\n",
    "loss_fn = unet_loss(bce_weight= 0.5, smooth = 0.1)\n",
    "learner = Learner(dls, model, loss_fn)\n",
    "learner_fit_params = copy.deepcopy(\n",
    "            parsed_config[\"learner\"][\"fit_params\"]\n",
    "        ) \n",
    "learner.fit(**learner_fit_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learner.model, \"/home/reza_voxelsafety_com/experiments/segmentation/data/fast_ai_floorsegmentation.pth\") # or save it's state_dict, better option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "print(len(test))\n",
    "dl_test = DataLoader(test, batch_size=16, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_test = DataLoader(test, batch_size=16, shuffle=False, num_workers=8)\n",
    "learner.model.eval()  # model is set for the test process\n",
    "iteration = 0\n",
    "for inputs, labels in dl_test:\n",
    "    inputs = inputs.to(device) # pasing input to the device\n",
    "    labels = labels.to(device) # passing label to the device\n",
    "    pred = learner.model(inputs.type(torch.float32)) # passing images to the model and predict\n",
    "\n",
    "    pred = pred.data.cpu().numpy()  # bring back the prediction from Gpu to cpu \n",
    "    if iteration % 100 == 0:\n",
    "\n",
    "        input_images_rgb = [input_to_image(x) for x in inputs.cpu()] # input rgb images for visualization\n",
    "        target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()] # mask labels (ground truth) to color image for visualization\n",
    "        pred_rgb = [masks_to_colorimg(x) for x in pred] # convert the prediction to images for visualization\n",
    "        \n",
    "        plot_imgs_align([input_images_rgb, target_masks_rgb, pred_rgb]) # plot images side by side\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    pred_label = [x for x in pred]\n",
    "\n",
    "    pred_label = np.asarray(pred_label)\n",
    "\n",
    "    metric = IoU(num_classes = 2)\n",
    "    metric.add(torch.from_numpy(pred_label), torch.from_numpy(labels)) # calculating IoU based on the library we cited \n",
    "    per_class_IoU, mean_IoU  = metric.value() \n",
    "    per_class_mean_accuracy.append(per_class_IoU) # append the per class IoU\n",
    "\n",
    "    print(\"Current Batch: per class IoU: {} and average IoU {}: \".format(per_class_IoU, mean_IoU)) # print the average and per class IoU for each batch of data\n",
    "    print(\"-----------------------------\")\n",
    "    mean_Accuracy.append(mean_IoU) # append the average Iou\n",
    "    iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "b02d07bb268aa9b4d81b2ed65a578e1b11ca4b632aaa460f3b5c67ba9b3c4648"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
