{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0534b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "torch.manual_seed(0)\n",
    "print(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94183f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):    \n",
    "    def __init__(self, data_dir = None):\n",
    "        self._data_dir = data_dir\n",
    "        data_dirs = [x[0] for x in os.walk(self._data_dir)][1:]\n",
    "        annotations = []\n",
    "        for i in range(len(data_dirs)):\n",
    "            data = json.load(open(f\"{data_dirs[i]}/annotations.json\"))\n",
    "            annotation = data['annotations']\n",
    "            img_dict = {}\n",
    "            for name in data['images']:\n",
    "                img_dict[name['id']] = name['file_name']\n",
    "            for k in range(len(annotation)):\n",
    "                annotation[k]['image_path'] = f\"{data_dirs[i]}/{img_dict[annotation[k]['image_id']]}\"\n",
    "            annotations.extend(annotation)\n",
    "        self._annotations_person = [ano for ano in annotations if ano['category_id'] == 0 and len(ano['keypoints'])==51]\n",
    "        self._pose_dict = {\"liftingbad\": 0, \n",
    "                           \"liftinggood\": 1, \n",
    "                           \"reachingbad\": 2, \n",
    "                           \"reachinggood\": 3, \n",
    "                           'randomrandom': 3}\n",
    "\n",
    "    def _process_pose(self, pose):\n",
    "        return self._pose_dict[pose]\n",
    "    \n",
    "    def _get_pose_size(self, keypoints, ratio):\n",
    "        hips_center = (keypoints[9,:] + keypoints[10,:]) / 2\n",
    "        shoulders_center = (keypoints[3,:] + keypoints[4,:]) / 2\n",
    "        torso_size = np.linalg.norm((shoulders_center - hips_center))\n",
    "        distance = np.linalg.norm((keypoints - hips_center), axis = 1)\n",
    "        max_d = np.max(distance)\n",
    "        pose_size = max(torso_size * ratio, max_d)\n",
    "        return pose_size\n",
    "    def _normalize_pose(self,keypoints):\n",
    "        data_p = np.expand_dims(np.array(keypoints), axis=1).reshape(-1,3)[:,0:2]\n",
    "        confidence = np.expand_dims(np.array(keypoints), axis=1).reshape(-1,3)[:,2]\n",
    "        confidence = np.expand_dims(np.delete(confidence,[3,4]), axis = 1)\n",
    "        data_p = np.delete(data_p,[3,4], axis = 0)\n",
    "        hip_center = (data_p[9,:] + data_p[10,:]) / 2\n",
    "        data_p = data_p - hip_center\n",
    "        pose_size = self._get_pose_size(data_p, 2)\n",
    "        data_p = data_p / pose_size\n",
    "        data_p = np.hstack((data_p,confidence))\n",
    "        return data_p.flatten()\n",
    "    def __getitem__(self, idx):\n",
    "        actor = self._annotations_person[idx]\n",
    "        if actor['keypoints'] is None:\n",
    "            print(\"is None\")\n",
    "        x = torch.tensor(self._normalize_pose(actor['keypoints']))\n",
    "        pose = actor['pose_category'] + actor['pose_subcategory']\n",
    "        y = self._process_pose(pose)\n",
    "        return x, y, actor['image_path'], np.array(actor['bbox'])\n",
    "    def __len__(self):\n",
    "        return len(self._annotations_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/ergonomic-Infinity-occlusion/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b827bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299380\n"
     ]
    }
   ],
   "source": [
    "print(len(pose_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840baa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 239504, 'val': 29938, 'test': 29938}\n"
     ]
    }
   ],
   "source": [
    "num_val= int(len(pose_data) * 0.1)\n",
    "num_train = len(pose_data) - 2 * num_val\n",
    "train, val, test = random_split(pose_data, [num_train, num_val, num_val])\n",
    "batch_size = 128\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "}\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train)\n",
    "dataset_sizes['val'] = len(val)\n",
    "dataset_sizes['test'] = len(test)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc1f43ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 2)\n",
      "(15, 1)\n",
      "size of one batch input data torch.Size([1, 45])\n",
      "size of one batch label data torch.Size([1])\n",
      "size of one batch image data ('/home/reza_voxelsafety_com/experiments/ergonomic/ergonomic-Infinity-occlusion/_americold-savannah-bloomingdale-0002/image.000000.rgb.png',)\n",
      "size of one batch image data tensor([[876.0100, 411.0100,  50.9800, 103.9800]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "dataloader_test = DataLoader(train, batch_size=1, shuffle=False)\n",
    "x, y, z, w = next(iter(dataloader_test))\n",
    "print(f\"size of one batch input data {x.shape}\")\n",
    "print(f\"size of one batch label data {y.shape}\")\n",
    "print(f\"size of one batch image data {z}\")\n",
    "print(f\"size of one batch image data {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6356988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datapoints: 299380\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of datapoints: {len(pose_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6e9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class PoseModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PoseModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        y = x.clone().detach()\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ab28aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import wandb\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, optimizer, config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    wandb.init(project =  \"ergo_ml_training\", entity = \"voxel-wandb\", config = config, tags = [config['tags']])\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=0.1)\n",
    "    config = wandb.config\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())   \n",
    "    best_accuracy = 0\n",
    "    model.to(device)\n",
    "    today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, config.num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels, _, _ in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs, y = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            if phase == 'val':\n",
    "                #print(\"val accuracy\", epoch_acc)\n",
    "                wandb.log({\"val loss\":epoch_loss})\n",
    "                wandb.log({\"val_accuracy\":epoch_acc})\n",
    "            if phase == 'train':\n",
    "                #print(\"train accuracy\", epoch_acc)\n",
    "                #print(\"train loss\", epoch_loss)\n",
    "                wandb.log({\"train loss\":epoch_loss})\n",
    "                wandb.log({\"train_accuracy\":epoch_acc})\n",
    "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_accuracy))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), f\"voxel_ergo_ml_{config.tags}_{today_date}.pth\")\n",
    "    wandb.join()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bfc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvoxel-wandb\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-20 22:35:47.077628: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-20 22:35:47.077671: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training/runs/gwe5t4j4\" target=\"_blank\">likely-breeze-29</a></strong> to <a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 1.0671208252990578 Acc: 0.6764479925178704\n",
      "val Loss: 0.9888864889819586 Acc: 0.7539247778742736\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 1.005391214827082 Acc: 0.7376453002872604\n",
      "val Loss: 0.9849732558134284 Acc: 0.757732647471441\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.9977447608683294 Acc: 0.7450397488142161\n",
      "val Loss: 0.978125858349889 Acc: 0.7645133275435901\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.9923392267789095 Acc: 0.750597067272363\n",
      "val Loss: 0.9842729127329826 Acc: 0.7583672924043022\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.9894386186844377 Acc: 0.7533569376711872\n",
      "val Loss: 0.9707516314860886 Acc: 0.7725966998463492\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.9867877218541564 Acc: 0.7559873739060726\n",
      "val Loss: 0.970629280244542 Acc: 0.7721624691028125\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.9849963537700127 Acc: 0.7578161533836596\n",
      "val Loss: 0.9688647740812146 Acc: 0.7740664039013962\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.982846961776227 Acc: 0.7599413788496227\n",
      "val Loss: 0.9654689176032121 Acc: 0.7777072616741266\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.9807804163444082 Acc: 0.7619371701516467\n",
      "val Loss: 0.9671854682202504 Acc: 0.7757699245106554\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.9800230288714205 Acc: 0.7629976952368228\n",
      "val Loss: 0.9720465993385881 Acc: 0.7705591555882156\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.9800861702509096 Acc: 0.762864085777273\n",
      "val Loss: 0.965596121138279 Acc: 0.7772396285657025\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.9785887011585609 Acc: 0.7640039414790568\n",
      "val Loss: 0.9630200949490242 Acc: 0.7797114035673726\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.9770060641961981 Acc: 0.7659872068942482\n",
      "val Loss: 0.9625016053849482 Acc: 0.7804128532300088\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.9771446346065963 Acc: 0.765765916226869\n",
      "val Loss: 0.9606250291979538 Acc: 0.7825506045828045\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.9740069335221655 Acc: 0.7688598102745675\n",
      "val Loss: 0.9635079992869485 Acc: 0.7790099539047365\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.9741018747262434 Acc: 0.7688973879350659\n",
      "val Loss: 0.9614462736048085 Acc: 0.7812145099873071\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.9739745191871877 Acc: 0.7690393479858374\n",
      "val Loss: 0.9578954972089336 Acc: 0.7854566103280113\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.9734969729929316 Acc: 0.7693817222259336\n",
      "val Loss: 0.9601423340885726 Acc: 0.7831852495156657\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.9736930409249629 Acc: 0.769243937470773\n",
      "val Loss: 0.9593540891926324 Acc: 0.783819894448527\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.9728656807247786 Acc: 0.7701458013227337\n",
      "val Loss: 0.9559561025085744 Acc: 0.7868929120181709\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.9710760010022249 Acc: 0.7719119513661568\n",
      "val Loss: 0.9579191744681932 Acc: 0.7853230008684615\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.9713298715668456 Acc: 0.7717115371768322\n",
      "val Loss: 0.9570621767712385 Acc: 0.7854232079631238\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.9703700853991631 Acc: 0.7724964927516869\n",
      "val Loss: 0.9587737001312927 Acc: 0.7844211370165008\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.9700918651445809 Acc: 0.7729891776337765\n",
      "val Loss: 0.9631996847670735 Acc: 0.7800454272162469\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.9689463138325483 Acc: 0.7741248580399492\n",
      "val Loss: 0.9551291809275391 Acc: 0.7876277640456945\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.970089850472547 Acc: 0.7728764446522814\n",
      "val Loss: 0.9623655674970256 Acc: 0.780513060324671\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.9691417470023885 Acc: 0.773790834391075\n",
      "val Loss: 0.9593332799883084 Acc: 0.7840203086378517\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.9676003319656963 Acc: 0.7754860044091122\n",
      "val Loss: 0.9555229281278561 Acc: 0.7879951900594563\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.9685772117810909 Acc: 0.7744296546195472\n",
      "val Loss: 0.9555655206696799 Acc: 0.7874941545861448\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.9669443964759097 Acc: 0.7761039481595298\n",
      "val Loss: 0.9554005590873408 Acc: 0.787894982964794\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.9670802494974523 Acc: 0.7758701316053177\n",
      "val Loss: 0.9545538574646307 Acc: 0.7887968468167547\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.9676337017071048 Acc: 0.7753983232012827\n",
      "val Loss: 0.9547186578368924 Acc: 0.7882624089785557\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.9672862287194912 Acc: 0.7757782751018772\n",
      "val Loss: 0.9546312804220196 Acc: 0.7885296278976552\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.9678413833228514 Acc: 0.7752146101944019\n",
      "val Loss: 0.9527355115354256 Acc: 0.7906673792504509\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.967117057923954 Acc: 0.7758826574921505\n",
      "val Loss: 0.9543697421532753 Acc: 0.7884628231678803\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.9671133586531994 Acc: 0.7760037410648675\n",
      "val Loss: 0.9545928326029921 Acc: 0.7885296278976552\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.96664842570407 Acc: 0.7765214777206226\n",
      "val Loss: 0.9550913490603384 Acc: 0.7882958113434432\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.9668799586267094 Acc: 0.7761164740463625\n",
      "val Loss: 0.9558596088919868 Acc: 0.7871601309372704\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.9656813467494216 Acc: 0.7772813815218118\n",
      "val Loss: 0.9532507486744438 Acc: 0.7900995390473646\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.965444312563751 Acc: 0.7775778275101878\n",
      "val Loss: 0.9522028397849618 Acc: 0.7908009887100007\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.9661590231031157 Acc: 0.7770016367158795\n",
      "val Loss: 0.9518573551292975 Acc: 0.7917362549268488\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.967012747896244 Acc: 0.7759953904736456\n",
      "val Loss: 0.9528589717960683 Acc: 0.7902331485069143\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.9660516739154406 Acc: 0.7770642661500434\n",
      "val Loss: 0.953111703680627 Acc: 0.7898657224931526\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.9649448946105413 Acc: 0.7781164406439977\n",
      "val Loss: 0.9529749695225337 Acc: 0.7901997461420269\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.9663945297589959 Acc: 0.7768095731177768\n",
      "val Loss: 0.9545905019017082 Acc: 0.7885296278976552\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.9666635595300376 Acc: 0.7764003941479057\n",
      "val Loss: 0.9543279247824196 Acc: 0.7887300420869798\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.966375516486539 Acc: 0.7767636448660565\n",
      "val Loss: 0.9499591723680735 Acc: 0.7932727637116709\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.9650451296022002 Acc: 0.7781164406439977\n",
      "val Loss: 0.9535311376437673 Acc: 0.7894982964793907\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.9653492004139181 Acc: 0.7778867993853965\n",
      "val Loss: 0.9520960541914759 Acc: 0.7911350123588751\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.9655553718409277 Acc: 0.7775778275101878\n",
      "val Loss: 0.9566396496101455 Acc: 0.7870933262074955\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.9644310434935398 Acc: 0.778680105551473\n",
      "val Loss: 0.9518136368365507 Acc: 0.7917028525619614\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.9641525456666293 Acc: 0.7789890774266819\n",
      "val Loss: 0.9506982685337962 Acc: 0.792437704589485\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.9642524914788024 Acc: 0.7789514997661835\n",
      "val Loss: 0.951633549622937 Acc: 0.7917028525619614\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.9637644288495131 Acc: 0.7795610929253791\n",
      "val Loss: 0.950213121542815 Acc: 0.7931391542521211\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.965088410398686 Acc: 0.7780162335493354\n",
      "val Loss: 0.9532426467750312 Acc: 0.7897321130336028\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.964413227936382 Acc: 0.7786592290734184\n",
      "val Loss: 0.9557127872141865 Acc: 0.7880285924243436\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.964920191226801 Acc: 0.778154018304496\n",
      "val Loss: 0.9546696159203965 Acc: 0.7884962255327678\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.9640070926140462 Acc: 0.7791602645467299\n",
      "val Loss: 0.951707979267637 Acc: 0.7914690360077494\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.9639492706016848 Acc: 0.7791226868862315\n",
      "val Loss: 0.9509789696540262 Acc: 0.7921704856703855\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.9640169233786525 Acc: 0.7791644398423409\n",
      "val Loss: 0.9513231059123841 Acc: 0.792137083305498\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.9650023559568656 Acc: 0.7782500501035474\n",
      "val Loss: 0.9541157486523326 Acc: 0.7890640657358542\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.9649278043991849 Acc: 0.7782959783552676\n",
      "val Loss: 0.9510151595723391 Acc: 0.7920702785757232\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.964150841118729 Acc: 0.7791352127730644\n",
      "val Loss: 0.9518172803650766 Acc: 0.7918030596566238\n",
      "Epoch 63/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9657284839970848 Acc: 0.777444218050638\n",
      "val Loss: 0.9557352306067295 Acc: 0.7875609593159196\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.9674290094739394 Acc: 0.7757866256930991\n",
      "val Loss: 0.9532911730032422 Acc: 0.7902331485069143\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.9657404695757167 Acc: 0.7774233415725834\n",
      "val Loss: 0.9512793098417278 Acc: 0.7920034738459484\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.963381338723955 Acc: 0.7798742400961989\n",
      "val Loss: 0.9508335557751015 Acc: 0.7923374974948226\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.9651089916408273 Acc: 0.7779828311844479\n",
      "val Loss: 0.9547607300634956 Acc: 0.7882958113434432\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.964041876338178 Acc: 0.7791602645467299\n",
      "val Loss: 0.9500420862276622 Acc: 0.7933395684414457\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.9637168111252604 Acc: 0.7794734117175497\n",
      "val Loss: 0.9549528444304687 Acc: 0.7879617876945688\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.9598151000056209 Acc: 0.7834524684347652\n",
      "val Loss: 0.9487427176418759 Acc: 0.7946422606720557\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.9564877261307317 Acc: 0.7867634778542322\n",
      "val Loss: 0.9480782626936499 Acc: 0.7953103079698043\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.955351515235655 Acc: 0.7879116841472377\n",
      "val Loss: 0.9476429904516239 Acc: 0.7959115505377781\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.9547556901521216 Acc: 0.7885880820362082\n",
      "val Loss: 0.947878260839136 Acc: 0.7957111363484535\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.9544232788150603 Acc: 0.7889179303894717\n",
      "val Loss: 0.9472968801960565 Acc: 0.7960117576324405\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.9542483433835197 Acc: 0.7890849422139088\n",
      "val Loss: 0.9474805518870316 Acc: 0.7957445387133409\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.9538631490774229 Acc: 0.7894732447057252\n",
      "val Loss: 0.9468377565794458 Acc: 0.7967800120248514\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.9538619197938412 Acc: 0.7895108223662236\n",
      "val Loss: 0.9466938535263578 Acc: 0.7969470238492886\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.9536487363456557 Acc: 0.7897112365555482\n",
      "val Loss: 0.9468994523322736 Acc: 0.7967132072950766\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.9536172315698324 Acc: 0.7897404636248246\n",
      "val Loss: 0.9469296247378262 Acc: 0.7966464025653017\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.9530499852152002 Acc: 0.7902749014630236\n",
      "val Loss: 0.9467085293772958 Acc: 0.7965795978355268\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.9530165913635555 Acc: 0.7903375308971876\n",
      "val Loss: 0.9460758670663793 Acc: 0.7970138285790634\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.9533636966730551 Acc: 0.7899367025185383\n",
      "val Loss: 0.9462551073198512 Acc: 0.7971474380386132\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.9531096443001322 Acc: 0.7901245908210301\n",
      "val Loss: 0.9466746840649644 Acc: 0.7963791836462022\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.9523116864830931 Acc: 0.7910849088115439\n",
      "val Loss: 0.9464059373930896 Acc: 0.7968134143897388\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.9529741808052363 Acc: 0.790370933262075\n",
      "val Loss: 0.9463558554275057 Acc: 0.7970472309439509\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.9525890727783461 Acc: 0.7906924310241166\n",
      "val Loss: 0.9461886854351415 Acc: 0.7970806333088383\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.9524102026558215 Acc: 0.7909053711002739\n",
      "val Loss: 0.945964414674889 Acc: 0.7974146569577126\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.9522408678031683 Acc: 0.7910515064466564\n",
      "val Loss: 0.9459208787996709 Acc: 0.7973478522279378\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.9523887933355764 Acc: 0.7910014028993253\n",
      "val Loss: 0.9457298061103714 Acc: 0.7979156924310241\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.9522295254322783 Acc: 0.7911433629500969\n",
      "val Loss: 0.9454186357957454 Acc: 0.7982831184447859\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.951893808281217 Acc: 0.791489912485804\n",
      "val Loss: 0.9460975217734798 Acc: 0.7971808404035006\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.9519796971448462 Acc: 0.7913396018438106\n",
      "val Loss: 0.9459896009721246 Acc: 0.7974814616874876\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.952145547779698 Acc: 0.7911767653149844\n",
      "val Loss: 0.9456924312068048 Acc: 0.7975148640523749\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.9518102145328798 Acc: 0.7914982630770259\n",
      "val Loss: 0.9452792536010642 Acc: 0.7980158995256864\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.9516077624134058 Acc: 0.7917362549268488\n",
      "val Loss: 0.9455304012101721 Acc: 0.7978154853363618\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.9518355960055626 Acc: 0.7915191395550806\n",
      "val Loss: 0.9452254983026411 Acc: 0.7980827042554614\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.9518538792455544 Acc: 0.7915107889638587\n",
      "val Loss: 0.9449968967905057 Acc: 0.7984167279043357\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.9518807647509998 Acc: 0.7914481595296947\n",
      "val Loss: 0.9451575759967269 Acc: 0.7985503373638854\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.9516744886166794 Acc: 0.7916068207629101\n",
      "val Loss: 0.94505575694862 Acc: 0.7984167279043357\n",
      "Training complete in 22m 45s\n",
      "Best val Acc: 0.798550\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5739... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6696d92a55dc44b28fd62583363f6b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 51.09MB of 51.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>val loss</td><td>█▆▅▄▄▄▄▃▃▃▄▃▃▂▃▂▂▂▂▂▂▂▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▅▅▆▆▆▅▆▆▇▆▇▇▇▆▇▇▇▆▇▇▆▇▇████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.95167</td></tr><tr><td>train_accuracy</td><td>0.79161</td></tr><tr><td>val loss</td><td>0.94506</td></tr><tr><td>val_accuracy</td><td>0.79842</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">likely-breeze-29</strong>: <a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training/runs/gwe5t4j4\" target=\"_blank\">https://wandb.ai/voxel-wandb/ergo_ml_training/runs/gwe5t4j4</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220520_223544-gwe5t4j4/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PoseModel(\n",
       "  (layer1): Linear(in_features=45, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "        'num_epochs': 100,\n",
    "        'tags': \"ergoMLLinearAlphaPoseModelOcclusion\",\n",
    "        'step': 70,\n",
    "}\n",
    "pose_model = PoseModel(45,4)\n",
    "optimizer = torch.optim.SGD(pose_model.parameters(), lr=0.1, momentum=0.9)\n",
    "train_model(pose_model, dataloaders, dataset_sizes, optimizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6264c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5455\n"
     ]
    }
   ],
   "source": [
    "pose_data_real = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/realdata_kp/')\n",
    "print(len(pose_data_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "349db8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2s4au5be) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 5067... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf57480f245a4a9b93354a072b0f4571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 51.09MB of 51.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">dauntless-snowflake-24</strong>: <a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/2s4au5be\" target=\"_blank\">https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/2s4au5be</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220520_230405-2s4au5be/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2s4au5be). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-20 23:05:46.515568: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-20 23:05:46.515616: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/1gfp9eoo\" target=\"_blank\">confused-firefly-25</a></strong> to <a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5660/528148940.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdisp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticks_rotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mTEST_TABLE_NAME\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_dt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, include_values, cmap, xticks_rotation, values_format, ax, colorbar)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolorbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         ax.set(xticks=np.arange(n_classes),\n\u001b[0m\u001b[1;32m    154\u001b[0m                \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmove_color_to_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/artist.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, props)\u001b[0m\n\u001b[1;32m   1062\u001b[0m                         raise AttributeError(f\"{type(self).__name__!r} object \"\n\u001b[1;32m   1063\u001b[0m                                              f\"has no property {k!r}\")\n\u001b[0;32m-> 1064\u001b[0;31m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpchanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[0;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_matplotlib/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[0;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1712\u001b[0m                     \u001b[0;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                     \u001b[0;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (5)."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "wandb.init(\n",
    "            project=\"ergo_synthetic_test\",\n",
    "            job_type=\"inference\",\n",
    "            entity=\"voxel-wandb\",\n",
    "        )\n",
    "TEST_TABLE_NAME = \"test_results\"\n",
    "columns = [\"Images\", \"Prediction\", \"GT\"]\n",
    "labels_type= [\"liftingbad\", \"liftinggood\", \"reachingbad\",'randomrandom']\n",
    "for klass in labels_type:\n",
    "    columns.append(\"score_\" + klass)\n",
    "test_dt = wandb.Table(columns=columns)\n",
    "model = PoseModel(45, 4)\n",
    "model.load_state_dict(\n",
    "    torch.load('/home/reza_voxelsafety_com/voxel/experimental/reza/Ergonomic/voxel_ergo_ml_ergoMLLinearAlphaPoseModelOcclusion_2022-05-20.pth')\n",
    ")\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloaders['test'] = DataLoader(pose_data_real, batch_size=1, shuffle=False, num_workers=8)\n",
    "running_corrects = 0\n",
    "model.to(device)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for inputs, labels, path, bbox in dataloaders['test']:\n",
    "    bbox = bbox.tolist()[0]\n",
    "    image = Image.open(path[0])\n",
    "    image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs,_ = model(inputs.float())\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_pred.append(preds.item())\n",
    "    y_true.append(labels.item())\n",
    "    row = [wandb.Image(image),\n",
    "            labels_type[preds], labels_type[labels]]\n",
    "    for c_i in outputs.data.cpu().numpy().tolist():\n",
    "        for c in c_i:\n",
    "            row.append(np.round(c, 4))\n",
    "    test_dt.add_data(*row)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "label_mapping = {\n",
    "    \"liftingbad\": 0, \n",
    "   \"liftinggood\": 1, \n",
    "   \"reachingbad\": 2, \n",
    "   \"reachinggood\": 3, \n",
    "   'randomrandom': 4\n",
    "}\n",
    "target_names = list(label_mapping.keys())\n",
    "\n",
    "cm = confusion_matrix(y_pred,y_true)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot(xticks_rotation=45)\n",
    "wandb.sklearn.plot_confusion_matrix(y_true, y_pred, target_names)\n",
    "wandb.log({TEST_TABLE_NAME: test_dt})\n",
    "accuracy_test = running_corrects.double() / len(pose_data_real)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a392537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test 0.6892758936755271\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = running_corrects.double() / len(pose_data_real)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "966958a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  liftingbad       0.16      0.45      0.24       228\n",
      " liftinggood       0.00      0.00      0.00         0\n",
      " reachingbad       0.14      0.38      0.21        40\n",
      "reachinggood       0.17      0.04      0.07      1189\n",
      "randomrandom       0.79      0.79      0.79      3998\n",
      "\n",
      "    accuracy                           0.61      5455\n",
      "   macro avg       0.25      0.33      0.26      5455\n",
      "weighted avg       0.62      0.61      0.60      5455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004f26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import xml.etree.ElementTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.data\n",
    "import cv2\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd01b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
