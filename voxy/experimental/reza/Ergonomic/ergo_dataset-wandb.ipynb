{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0534b80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f4010fc0690>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94183f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):    \n",
    "    def __init__(self, data_dir = None):\n",
    "        self._data_dir = data_dir\n",
    "        data_dirs = [x[0] for x in os.walk(self._data_dir)][1:]\n",
    "        annotations = []\n",
    "        for i in range(len(data_dirs)):\n",
    "            data = json.load(open(f\"{data_dirs[i]}/annotations.json\"))\n",
    "            annotation = data['annotations']\n",
    "            img_dict = {}\n",
    "            for name in data['images']:\n",
    "                img_dict[name['id']] = name['file_name']\n",
    "            for k in range(len(annotation)):\n",
    "                annotation[k]['image_path'] = f\"{data_dirs[i]}/{img_dict[annotation[k]['image_id']]}\"\n",
    "            annotations.extend(annotation)\n",
    "        self._annotations_person = [ano for ano in annotations if ano['category_id'] == 0 and len(ano['keypoints'])==51]\n",
    "        self._pose_dict = {\"liftingbad\": 0, \n",
    "                           \"liftinggood\": 1, \n",
    "                           \"reachingbad\": 2, \n",
    "                           \"reachinggood\": 3, \n",
    "                           'randomrandom': 4}\n",
    "\n",
    "    def _process_pose(self, pose):\n",
    "        return self._pose_dict[pose]\n",
    "    \n",
    "    def _get_pose_size(self, keypoints, ratio):\n",
    "        hips_center = (keypoints[9,:] + keypoints[10,:]) / 2\n",
    "        shoulders_center = (keypoints[3,:] + keypoints[4,:]) / 2\n",
    "        torso_size = np.linalg.norm((shoulders_center - hips_center))\n",
    "        distance = np.linalg.norm((keypoints - hips_center), axis = 1)\n",
    "        max_d = np.max(distance)\n",
    "        pose_size = max(torso_size * ratio, max_d)\n",
    "        return pose_size\n",
    "    def _normalize_pose(self,keypoints):\n",
    "        data_p = np.expand_dims(np.array(keypoints), axis=1).reshape(-1,3)[:,0:2]\n",
    "        data_p = np.delete(data_p,[3,4], axis = 0)\n",
    "        hip_center = (data_p[9,:] + data_p[10,:]) / 2\n",
    "        data_p = data_p - hip_center\n",
    "        pose_size = self._get_pose_size(data_p, 2)\n",
    "        data_p = data_p / pose_size\n",
    "        return data_p.flatten()\n",
    "    def __getitem__(self, idx):\n",
    "        actor = self._annotations_person[idx]\n",
    "        if actor['keypoints'] is None:\n",
    "            print(\"is None\")\n",
    "        x = torch.tensor(self._normalize_pose(actor['keypoints']))\n",
    "#         image =  Image.open(actor['image_path'])\n",
    "#         actor_img = np.asarray(image.crop((actor['bbox'][0], actor['bbox'][1], \n",
    "#                                 actor['bbox'][0] + actor['bbox'][2], \n",
    "#                                 actor['bbox'][1] + actor['bbox'][3])))[...,:3]\n",
    "        pose = actor['pose_category'] + actor['pose_subcategory']\n",
    "        y = self._process_pose(pose)\n",
    "        return x, y, actor['image_path'], np.array(actor['bbox'])\n",
    "    def __len__(self):\n",
    "        return len(self._annotations_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeab75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/ergonomic-Infinity-occlusion/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b827bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299380\n"
     ]
    }
   ],
   "source": [
    "print(len(pose_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "840baa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 239504, 'val': 29938, 'test': 29938}\n"
     ]
    }
   ],
   "source": [
    "num_val= int(len(pose_data) * 0.1)\n",
    "num_train = len(pose_data) - 2 * num_val\n",
    "train, val, test = random_split(pose_data, [num_train, num_val, num_val])\n",
    "batch_size = 128\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "}\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train)\n",
    "dataset_sizes['val'] = len(val)\n",
    "dataset_sizes['test'] = len(test)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6356988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datapoints: 299380\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of datapoints: {len(pose_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f6e9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class PoseModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PoseModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        y = x.clone().detach()\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ab28aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import wandb\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, optimizer, config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    wandb.init(project =  \"ergo_ml_training\", entity = \"voxel-wandb\", config = config, tags = [config['tags']])\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=0.1)\n",
    "    config = wandb.config\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())   \n",
    "    best_accuracy = 0\n",
    "    model.to(device)\n",
    "    today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, config.num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels, _, _ in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs, y = model(inputs.float())\n",
    "                    print(y.shape)\n",
    "                    input()\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            if phase == 'val':\n",
    "                #print(\"val accuracy\", epoch_acc)\n",
    "                wandb.log({\"val loss\":epoch_loss})\n",
    "                wandb.log({\"val_accuracy\":epoch_acc})\n",
    "            if phase == 'train':\n",
    "                #print(\"train accuracy\", epoch_acc)\n",
    "                #print(\"train loss\", epoch_loss)\n",
    "                wandb.log({\"train loss\":epoch_loss})\n",
    "                wandb.log({\"train_accuracy\":epoch_acc})\n",
    "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_accuracy))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), f\"voxel_ergo_ml_{config.tags}_{today_date}.pth\")\n",
    "    wandb.join()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfc836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:otpk0tnt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29903... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74d10a5c0e24eba9a1aacb44fc30e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 241.96MB of 241.96MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 5437 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">polished-forest-21</strong>: <a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/otpk0tnt\" target=\"_blank\">https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/otpk0tnt</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220520_164454-otpk0tnt/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:otpk0tnt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-20 17:00:48.324777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-20 17:00:48.324828: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training/runs/krm0nuqi\" target=\"_blank\">brisk-dream-21</a></strong> to <a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "torch.Size([128, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "        'num_epochs': 100,\n",
    "        'tags': \"ergoMLLinearAlphaPoseModelOcclusion\",\n",
    "        'step': 70,\n",
    "}\n",
    "pose_model = PoseModel(30,5)\n",
    "optimizer = torch.optim.SGD(pose_model.parameters(), lr=0.1, momentum=0.9)\n",
    "train_model(pose_model, dataloaders, dataset_sizes, optimizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6264c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5455\n"
     ]
    }
   ],
   "source": [
    "pose_data_real = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/realdata_kp0.5/')\n",
    "print(len(pose_data_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349db8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "wandb.init(\n",
    "            project=\"ergo_synthetic_test\",\n",
    "            job_type=\"inference\",\n",
    "            entity=\"voxel-wandb\",\n",
    "        )\n",
    "TEST_TABLE_NAME = \"test_results\"\n",
    "columns = [\"Images\", \"Prediction\", \"GT\"]\n",
    "labels_type= [\"liftingbad\", \"liftinggood\", \"reachingbad\", \"reachinggood\",'randomrandom']\n",
    "for klass in labels_type:\n",
    "    columns.append(\"score_\" + klass)\n",
    "test_dt = wandb.Table(columns=columns)\n",
    "model = PoseModel(30, 5)\n",
    "model.load_state_dict(\n",
    "    torch.load('/home/reza_voxelsafety_com/voxel/experimental/reza/Ergonomic/voxel_ergo_ml_ergoMLLinearAlphaPoseModelOcclusion_2022-05-20.pth')\n",
    ")\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloaders['test'] = DataLoader(test, batch_size=1, shuffle=False, num_workers=8)\n",
    "running_corrects = 0\n",
    "model.to(device)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for inputs, labels, path, bbox in dataloaders['test']:\n",
    "    bbox = bbox.tolist()[0]\n",
    "    image = Image.open(path[0])\n",
    "    image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs.float())\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_pred.append(preds.item())\n",
    "    y_true.append(labels.item())\n",
    "    row = [wandb.Image(image),\n",
    "            labels_type[preds], labels_type[labels]]\n",
    "    for c_i in outputs.data.cpu().numpy().tolist():\n",
    "        for c in c_i:\n",
    "            row.append(np.round(c, 4))\n",
    "    test_dt.add_data(*row)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "label_mapping = {\n",
    "    \"liftingbad\": 0, \n",
    "   \"liftinggood\": 1, \n",
    "   \"reachingbad\": 2, \n",
    "   \"reachinggood\": 3, \n",
    "   'randomrandom': 4\n",
    "}\n",
    "target_names = list(label_mapping.keys())\n",
    "\n",
    "cm = confusion_matrix(y_pred,y_true)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "disp.plot(xticks_rotation=45)\n",
    "wandb.sklearn.plot_confusion_matrix(y_true, y_pred, target_names)\n",
    "wandb.log({TEST_TABLE_NAME: test_dt})\n",
    "accuracy_test = running_corrects.double() / len(test)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a392537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test 0.6892758936755271\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = running_corrects.double() / len(pose_data_real)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "966958a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  liftingbad       0.16      0.45      0.24       228\n",
      " liftinggood       0.00      0.00      0.00         0\n",
      " reachingbad       0.14      0.38      0.21        40\n",
      "reachinggood       0.17      0.04      0.07      1189\n",
      "randomrandom       0.79      0.79      0.79      3998\n",
      "\n",
      "    accuracy                           0.61      5455\n",
      "   macro avg       0.25      0.33      0.26      5455\n",
      "weighted avg       0.62      0.61      0.60      5455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004f26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import xml.etree.ElementTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.data\n",
    "import cv2\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd01b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
