{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0534b80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f452c038690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94183f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseDataset(Dataset):    \n",
    "    def __init__(self, data_dir = None):\n",
    "        self._data_dir = data_dir\n",
    "        data_dirs = [x[0] for x in os.walk(self._data_dir)][1:]\n",
    "        annotations = []\n",
    "        for i in range(len(data_dirs)):\n",
    "            data = json.load(open(f\"{data_dirs[i]}/annotations.json\"))\n",
    "            annotation = data['annotations']\n",
    "            img_dict = {}\n",
    "            for name in data['images']:\n",
    "                img_dict[name['id']] = name['file_name']\n",
    "            for k in range(len(annotation)):\n",
    "                annotation[k]['image_path'] = f\"{data_dirs[i]}/{img_dict[annotation[k]['image_id']]}\"\n",
    "            annotations.extend(annotation)\n",
    "        self._annotations_person = [ano for ano in annotations if ano['category_id'] == 0 \n",
    "                                    and len(ano['keypoints'])==51 and ano['pose_category']!=\"lifting\"]\n",
    "        self._pose_dict = {\"reachingbad\": 0, \n",
    "                           \"reachinggood\": 1, \n",
    "                           'randomrandom': 1}\n",
    "\n",
    "    def _process_pose(self, pose):\n",
    "        return self._pose_dict[pose]\n",
    "    \n",
    "    def _get_pose_size(self, keypoints, ratio):\n",
    "        hips_center = (keypoints[9,:] + keypoints[10,:]) / 2\n",
    "        shoulders_center = (keypoints[3,:] + keypoints[4,:]) / 2\n",
    "        torso_size = np.linalg.norm((shoulders_center - hips_center))\n",
    "        distance = np.linalg.norm((keypoints - hips_center), axis = 1)\n",
    "        max_d = np.max(distance)\n",
    "        pose_size = max(torso_size * ratio, max_d)\n",
    "        return pose_size\n",
    "    def _normalize_pose(self,keypoints):\n",
    "        data_p = np.expand_dims(np.array(keypoints), axis=1).reshape(-1,3)[:,0:2]\n",
    "        data_p = np.delete(data_p,[3,4], axis = 0)\n",
    "        hip_center = (data_p[9,:] + data_p[10,:]) / 2\n",
    "        data_p = data_p - hip_center\n",
    "        pose_size = self._get_pose_size(data_p, 2)\n",
    "        data_p = data_p / pose_size\n",
    "        return data_p.flatten()\n",
    "    def __getitem__(self, idx):\n",
    "        actor = self._annotations_person[idx]\n",
    "        if actor['keypoints'] is None:\n",
    "            print(\"is None\")\n",
    "        x = torch.tensor(self._normalize_pose(actor['keypoints']))\n",
    "        pose = actor['pose_category'] + actor['pose_subcategory']\n",
    "        y = self._process_pose(pose)\n",
    "        return x, y, actor['image_path'], np.array(actor['bbox'])\n",
    "    def __len__(self):\n",
    "        return len(self._annotations_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeab75d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_data = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/ergonomic-Infinity/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b827bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39891\n"
     ]
    }
   ],
   "source": [
    "print(len(pose_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840baa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 31913, 'val': 3989, 'test': 3989}\n"
     ]
    }
   ],
   "source": [
    "num_val= int(len(pose_data) * 0.1)\n",
    "num_train = len(pose_data) - 2 * num_val\n",
    "train, val, test = random_split(pose_data, [num_train, num_val, num_val])\n",
    "batch_size = 128\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "    'val': DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8),\n",
    "}\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train)\n",
    "dataset_sizes['val'] = len(val)\n",
    "dataset_sizes['test'] = len(test)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6356988d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datapoints: 39891\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of datapoints: {len(pose_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6e9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class PoseModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(PoseModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x)\n",
    "        y = x.clone().detach()\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab28aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import wandb\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, optimizer, config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    wandb.init(project =  \"ergo_ml_training\", entity = \"voxel-wandb\", config = config, tags = [config['tags']])\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=config['step'], gamma=0.1)\n",
    "    config = wandb.config\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())   \n",
    "    best_accuracy = 0\n",
    "    model.to(device)\n",
    "    today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "    for epoch in range(config.num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, config.num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels, _, _ in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs, y = model(inputs.float())\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            if phase == 'val':\n",
    "                #print(\"val accuracy\", epoch_acc)\n",
    "                wandb.log({\"val loss\":epoch_loss})\n",
    "                wandb.log({\"val_accuracy\":epoch_acc})\n",
    "            if phase == 'train':\n",
    "                #print(\"train accuracy\", epoch_acc)\n",
    "                #print(\"train loss\", epoch_loss)\n",
    "                wandb.log({\"train loss\":epoch_loss})\n",
    "                wandb.log({\"train_accuracy\":epoch_acc})\n",
    "            print(f'{phase} Loss: {epoch_loss} Acc: {epoch_acc}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_accuracy:\n",
    "                best_accuracy = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_accuracy))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), f\"voxel_ergo_ml_{config.tags}_{today_date}.pth\")\n",
    "    wandb.join()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bfc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvoxel-wandb\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-23 17:10:11.135427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-23 17:10:11.135477: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training/runs/3fwk3ghh\" target=\"_blank\">stellar-salad-31</a></strong> to <a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.43309016281680685 Acc: 0.8807695923291449\n",
      "val Loss: 0.34760062086848154 Acc: 0.9639007269992479\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.3479042258905654 Acc: 0.9657819697302039\n",
      "val Loss: 0.3457638880503629 Acc: 0.9656555527701177\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.34484612985353275 Acc: 0.9685394666750227\n",
      "val Loss: 0.3455205225920611 Acc: 0.9661569315617948\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.3438969982522808 Acc: 0.9690408297558988\n",
      "val Loss: 0.3428679918041502 Acc: 0.9699172724993732\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.3434600686814431 Acc: 0.9694168520665559\n",
      "val Loss: 0.3439339399188346 Acc: 0.9684131361243419\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.3420197989255712 Acc: 0.9708896061166296\n",
      "val Loss: 0.3430532626443472 Acc: 0.9699172724993732\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.3408994084556851 Acc: 0.971986337856046\n",
      "val Loss: 0.3400177029656061 Acc: 0.9724241664577588\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.34017899706509136 Acc: 0.9726757120922508\n",
      "val Loss: 0.34206955848734727 Acc: 0.9704186512910503\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.3401587229120852 Acc: 0.9724250305518127\n",
      "val Loss: 0.3376524866329575 Acc: 0.97568312860366\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.3381942525602674 Acc: 0.974837840378529\n",
      "val Loss: 0.33750469527258914 Acc: 0.9751817498119829\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.3383762821710626 Acc: 0.9743991476827625\n",
      "val Loss: 0.3372555230831735 Acc: 0.9749310604161443\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.33772885689399074 Acc: 0.9752451978817409\n",
      "val Loss: 0.3380018431729737 Acc: 0.9739283028327901\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.33665812577064375 Acc: 0.9764672703913765\n",
      "val Loss: 0.3356151107141146 Acc: 0.977939333166207\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.3360966913869245 Acc: 0.9769686334722526\n",
      "val Loss: 0.33397884113682813 Acc: 0.9791927801453998\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.3359964149114732 Acc: 0.9769059630871432\n",
      "val Loss: 0.33679459027163394 Acc: 0.9759338179994985\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.33612729393430674 Acc: 0.9768432927020336\n",
      "val Loss: 0.33342956096554016 Acc: 0.9796941589370769\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.33608789306206477 Acc: 0.9769059630871432\n",
      "val Loss: 0.3324961720641976 Acc: 0.9804462271245925\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.33480156441724457 Acc: 0.9780340300191145\n",
      "val Loss: 0.33342886509737535 Acc: 0.9794434695412383\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.33430704583244025 Acc: 0.9789114154106476\n",
      "val Loss: 0.33242029746572727 Acc: 0.9809476059162696\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.3342111252540819 Acc: 0.9787547394478738\n",
      "val Loss: 0.3321955523923633 Acc: 0.9811982953121082\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.33386329887553035 Acc: 0.9793187729138595\n",
      "val Loss: 0.3311531911460521 Acc: 0.9824517422913011\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.33267899576713594 Acc: 0.9801021527277285\n",
      "val Loss: 0.3313007588657289 Acc: 0.9819503634996238\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.3332611067309344 Acc: 0.9798201359947356\n",
      "val Loss: 0.33251216549656987 Acc: 0.9811982953121082\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.33284956527040926 Acc: 0.9802274934979475\n",
      "val Loss: 0.3336733028490641 Acc: 0.9789420907495612\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.33292277520718877 Acc: 0.9801021527277285\n",
      "val Loss: 0.3319634097609851 Acc: 0.9809476059162696\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.3324004135087608 Acc: 0.9807288565788237\n",
      "val Loss: 0.3291738995127464 Acc: 0.9839558786663324\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.3316446109297387 Acc: 0.9815122363926926\n",
      "val Loss: 0.33030045710132366 Acc: 0.9824517422913011\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.3318160433453282 Acc: 0.9807601917713784\n",
      "val Loss: 0.3308105633264199 Acc: 0.9816996741037853\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.33174536428717355 Acc: 0.9811362140820356\n",
      "val Loss: 0.33033142053384656 Acc: 0.9832038104788167\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.3304478641381944 Acc: 0.9828283144799924\n",
      "val Loss: 0.3286256993002209 Acc: 0.9842065680621709\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.3314186528601037 Acc: 0.9813868956224736\n",
      "val Loss: 0.32901803501777765 Acc: 0.9839558786663324\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.33091726915676384 Acc: 0.9820449346661235\n",
      "val Loss: 0.3297608634393955 Acc: 0.9832038104788167\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.33084726217165633 Acc: 0.9823896217842258\n",
      "val Loss: 0.32807897745173326 Acc: 0.984707946853848\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.3306365089372351 Acc: 0.981982264281014\n",
      "val Loss: 0.3302207271402478 Acc: 0.9816996741037853\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.3303542321770417 Acc: 0.9826403033246639\n",
      "val Loss: 0.3288074387407865 Acc: 0.9842065680621709\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.3309057299026113 Acc: 0.9820449346661235\n",
      "val Loss: 0.32883526115496375 Acc: 0.9849586362496866\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.3316760310803443 Acc: 0.981198884467145\n",
      "val Loss: 0.33035268490551767 Acc: 0.9827024316871396\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.33143463476988516 Acc: 0.9811362140820356\n",
      "val Loss: 0.3297500034925423 Acc: 0.9827024316871396\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.3312494251495937 Acc: 0.9816062419703568\n",
      "val Loss: 0.32738974906352863 Acc: 0.9854600150413637\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.33101317768177163 Acc: 0.9818255883182402\n",
      "val Loss: 0.33071179435826326 Acc: 0.9816996741037853\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.3311033528789 Acc: 0.9820135994735687\n",
      "val Loss: 0.3305238303489092 Acc: 0.9822010528954624\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.3301139528219147 Acc: 0.9825462977469996\n",
      "val Loss: 0.328129765233709 Acc: 0.9849586362496866\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.33012606140006784 Acc: 0.9828596496725472\n",
      "val Loss: 0.32932442433405534 Acc: 0.9832038104788167\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.32950569414298314 Acc: 0.9837056998715257\n",
      "val Loss: 0.32676208365169734 Acc: 0.986964151416395\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.3284007518361999 Acc: 0.9846144204556136\n",
      "val Loss: 0.32605252177173194 Acc: 0.9867134620205564\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.3283552446452542 Acc: 0.9848651019960517\n",
      "val Loss: 0.32923051153068467 Acc: 0.9837051892704938\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.32930583099075306 Acc: 0.9837997054491899\n",
      "val Loss: 0.32860582534996124 Acc: 0.9842065680621709\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.3285812764983532 Acc: 0.9843637389151756\n",
      "val Loss: 0.32882790202842255 Acc: 0.9834544998746553\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.329095377126184 Acc: 0.9837056998715257\n",
      "val Loss: 0.3287248057540899 Acc: 0.9837051892704938\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.3295466564531496 Acc: 0.98314166640554\n",
      "val Loss: 0.3260826647177051 Acc: 0.986964151416395\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.3300304806950032 Acc: 0.9827343089023282\n",
      "val Loss: 0.3284371740150404 Acc: 0.9844572574580095\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.33084714658108016 Acc: 0.9817002475480211\n",
      "val Loss: 0.32711910783841097 Acc: 0.9862120832288793\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.32955842303160654 Acc: 0.9836430294864161\n",
      "val Loss: 0.32715698162933793 Acc: 0.9859613938330408\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.32899926270712576 Acc: 0.9838310406417448\n",
      "val Loss: 0.32696238834028946 Acc: 0.9859613938330408\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.3277450274262034 Acc: 0.9853978002694826\n",
      "val Loss: 0.32648326270142186 Acc: 0.986964151416395\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.3282945302041289 Acc: 0.9849904427662708\n",
      "val Loss: 0.3283118713496771 Acc: 0.984707946853848\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.3296995377154343 Acc: 0.9829223200576567\n",
      "val Loss: 0.3263307266529415 Acc: 0.9867134620205564\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.3279425402236434 Acc: 0.984833766803497\n",
      "val Loss: 0.32709642771821057 Acc: 0.9859613938330408\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.3286638356075431 Acc: 0.9842070629524018\n",
      "val Loss: 0.32666315310549454 Acc: 0.9864627726247179\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.328352000143282 Acc: 0.9844577444928398\n",
      "val Loss: 0.32602873776275193 Acc: 0.9874655302080722\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.3284611513904301 Acc: 0.9843950741077303\n",
      "val Loss: 0.32632366653581285 Acc: 0.9859613938330408\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.32809021807589517 Acc: 0.9850217779588255\n",
      "val Loss: 0.32679274522083746 Acc: 0.9862120832288793\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.3275647260643451 Acc: 0.9853978002694826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.32640970815659526 Acc: 0.986964151416395\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.3271820122241316 Acc: 0.9860245041205777\n",
      "val Loss: 0.33067185530898024 Acc: 0.9827024316871396\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.32713783413850683 Acc: 0.9859304985429135\n",
      "val Loss: 0.3267762278383852 Acc: 0.9864627726247179\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.32837394430588573 Acc: 0.9845517500705041\n",
      "val Loss: 0.32645809761740924 Acc: 0.9859613938330408\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.3283881614788934 Acc: 0.9845517500705041\n",
      "val Loss: 0.32873646682980484 Acc: 0.9839558786663324\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.3291198883573477 Acc: 0.9835803591013067\n",
      "val Loss: 0.32727356393643864 Acc: 0.9854600150413637\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.328554274070208 Acc: 0.9844264093002851\n",
      "val Loss: 0.32578630996067204 Acc: 0.9874655302080722\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.32745360728679296 Acc: 0.9855858114248112\n",
      "val Loss: 0.3249925949066078 Acc: 0.9879669089997493\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.3256333763240868 Acc: 0.9873405822078777\n",
      "val Loss: 0.32469284942377835 Acc: 0.9882175983955878\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.32507317970842947 Acc: 0.9878419452887538\n",
      "val Loss: 0.32449354683734266 Acc: 0.9884682877914264\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.32446737320694397 Acc: 0.9882806379845204\n",
      "val Loss: 0.3241806391950657 Acc: 0.9889696665831035\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.32398773800821346 Acc: 0.9890953529909441\n",
      "val Loss: 0.32414785153766 Acc: 0.9887189771872649\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.3237757283116905 Acc: 0.9895340456867107\n",
      "val Loss: 0.32381898181185625 Acc: 0.9894710453747806\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.32307991669353797 Acc: 0.9903174255005797\n",
      "val Loss: 0.32368766051182685 Acc: 0.9897217347706191\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.3236922836253656 Acc: 0.9894087049164917\n",
      "val Loss: 0.32400651857738777 Acc: 0.9889696665831035\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.3231392961105281 Acc: 0.9900980791526963\n",
      "val Loss: 0.32385443131198677 Acc: 0.9894710453747806\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.323588181742191 Acc: 0.9896907216494845\n",
      "val Loss: 0.3240913719230201 Acc: 0.989220355978942\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.32344300210769156 Acc: 0.9896907216494845\n",
      "val Loss: 0.32390078456218335 Acc: 0.9889696665831035\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.3232642788980111 Acc: 0.9897847272271488\n",
      "val Loss: 0.3241405993677614 Acc: 0.9887189771872649\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.32319006477247836 Acc: 0.9898160624197035\n",
      "val Loss: 0.32395925302050055 Acc: 0.9894710453747806\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.32314815703119104 Acc: 0.9901920847303607\n",
      "val Loss: 0.3239374775565576 Acc: 0.9887189771872649\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.3231366936999793 Acc: 0.9899727383824773\n",
      "val Loss: 0.32392231964264095 Acc: 0.9889696665831035\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.3225975089150804 Acc: 0.9905994422335725\n",
      "val Loss: 0.32409038335107326 Acc: 0.9887189771872649\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.32250862513729156 Acc: 0.990662112618682\n",
      "val Loss: 0.3238400865031472 Acc: 0.9894710453747806\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.32307912102018443 Acc: 0.9901920847303607\n",
      "val Loss: 0.3239176275213729 Acc: 0.9889696665831035\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.32248633064307913 Acc: 0.9908501237740106\n",
      "val Loss: 0.32380953627620074 Acc: 0.9897217347706191\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.3230643443333913 Acc: 0.9899100679973678\n",
      "val Loss: 0.3239227653027896 Acc: 0.9889696665831035\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.3226253742293937 Acc: 0.9904741014633535\n",
      "val Loss: 0.323678926346923 Acc: 0.9897217347706191\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.3231923887615564 Acc: 0.9899727383824773\n",
      "val Loss: 0.32396133675495165 Acc: 0.9889696665831035\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.3226664766327947 Acc: 0.990536771848463\n",
      "val Loss: 0.32423036211742495 Acc: 0.9887189771872649\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.3228750315058576 Acc: 0.9902234199229154\n",
      "val Loss: 0.32408693454474186 Acc: 0.9887189771872649\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.3227125177805379 Acc: 0.9903174255005797\n",
      "val Loss: 0.32377274292965946 Acc: 0.9889696665831035\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.32281935722923616 Acc: 0.9904741014633535\n",
      "val Loss: 0.324034411085671 Acc: 0.9887189771872649\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.3227688699845844 Acc: 0.990536771848463\n",
      "val Loss: 0.3235661011795317 Acc: 0.9887189771872649\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.3229528467134386 Acc: 0.9901920847303607\n",
      "val Loss: 0.323578335895787 Acc: 0.989220355978942\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.32260133492981363 Acc: 0.9906307774261273\n",
      "val Loss: 0.3237870778168434 Acc: 0.9887189771872649\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.3228381203756409 Acc: 0.9904114310782439\n",
      "val Loss: 0.32393540714312447 Acc: 0.9889696665831035\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.3220477398726932 Acc: 0.9913828220474414\n",
      "val Loss: 0.3241413827900541 Acc: 0.9887189771872649\n",
      "Training complete in 3m 55s\n",
      "Best val Acc: 0.989722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23684... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d151cfe43e3e43feabac4a5e2d5d7908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 25.25MB of 25.25MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███████████████████</td></tr><tr><td>val loss</td><td>█▇▇▆▅▅▄▄▃▄▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▆▇▇▆▇▆▆▇▇▇▇▇▆▆▇████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>0.32205</td></tr><tr><td>train_accuracy</td><td>0.99138</td></tr><tr><td>val loss</td><td>0.32414</td></tr><tr><td>val_accuracy</td><td>0.98872</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">stellar-salad-31</strong>: <a href=\"https://wandb.ai/voxel-wandb/ergo_ml_training/runs/3fwk3ghh\" target=\"_blank\">https://wandb.ai/voxel-wandb/ergo_ml_training/runs/3fwk3ghh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220523_171008-3fwk3ghh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PoseModel(\n",
       "  (layer1): Linear(in_features=30, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (layer3): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "        'num_epochs': 100,\n",
    "        'tags': \"ergoMLLinearAlphaPoseModelOverreaching\",\n",
    "        'step': 70,\n",
    "}\n",
    "pose_model = PoseModel(30,2)\n",
    "optimizer = torch.optim.SGD(pose_model.parameters(), lr=0.1, momentum=0.9)\n",
    "train_model(pose_model, dataloaders, dataset_sizes, optimizer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6264c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5227\n"
     ]
    }
   ],
   "source": [
    "pose_data_real = PoseDataset(data_dir = '/home/reza_voxelsafety_com/experiments/ergonomic/realdata/')\n",
    "print(len(pose_data_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "349db8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3nq7ljby) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22452... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af44440f1cbb42c9bf3138c29fb4b58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 70.72MB of 70.72MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 3991 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">wobbly-glitter-29</strong>: <a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/3nq7ljby\" target=\"_blank\">https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/3nq7ljby</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220523_171723-3nq7ljby/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3nq7ljby). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.16 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-05-23 17:23:40.553077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-23 17:23:40.553129: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test/runs/332821lm\" target=\"_blank\">pretty-gorge-30</a></strong> to <a href=\"https://wandb.ai/voxel-wandb/ergo_synthetic_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test 0.98890376889229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "wandb.init(\n",
    "            project=\"ergo_synthetic_test\",\n",
    "            job_type=\"inference\",\n",
    "            entity=\"voxel-wandb\",\n",
    "        )\n",
    "TEST_TABLE_NAME = \"test_results\"\n",
    "columns = [\"Images\", \"Prediction\", \"GT\"]\n",
    "labels_type= [\"reachingbad\", \"reachinggoodrandomrandom\"]\n",
    "for klass in labels_type:\n",
    "    columns.append(\"score_\" + klass)\n",
    "test_dt = wandb.Table(columns=columns)\n",
    "model = PoseModel(30, 2)\n",
    "model.load_state_dict(\n",
    "    torch.load('/home/reza_voxelsafety_com/voxel/experimental/reza/Ergonomic/voxel_ergo_ml_ergoMLLinearAlphaPoseModelOverreaching_2022-05-23.pth')\n",
    ")\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataloaders_test = DataLoader(pose_data_real, batch_size=1, shuffle=False, num_workers=8)\n",
    "running_corrects = 0\n",
    "model.to(device)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for inputs, labels, path, bbox in dataloaders_test:\n",
    "    bbox = bbox.tolist()[0]\n",
    "    image = Image.open(path[0])\n",
    "    image = image.crop((bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs,_ = model(inputs.float())\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    y_pred.append(preds.item())\n",
    "    y_true.append(labels.item())\n",
    "    row = [wandb.Image(image),\n",
    "            labels_type[preds], labels_type[labels]]\n",
    "    for c_i in outputs.data.cpu().numpy().tolist():\n",
    "        for c in c_i:\n",
    "            row.append(np.round(c, 4))\n",
    "    test_dt.add_data(*row)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "label_mapping = {\n",
    "   \"reachingbad\": 0, \n",
    "   \"reachinggood\": 1, \n",
    "   'randomrandom': 1\n",
    "}\n",
    "target_names = list(label_mapping.keys())\n",
    "\n",
    "cm = confusion_matrix(y_pred,y_true)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "# disp.plot(xticks_rotation=45)\n",
    "wandb.sklearn.plot_confusion_matrix(y_true, y_pred, target_names)\n",
    "wandb.log({TEST_TABLE_NAME: test_dt})\n",
    "accuracy_test = running_corrects.double() / len(pose_data_real)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a392537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test 0.9899724241664577\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = running_corrects.double() / len(test)\n",
    "print(f\"Accuracy test {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "966958a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  liftingbad       0.16      0.45      0.24       228\n",
      " liftinggood       0.00      0.00      0.00         0\n",
      " reachingbad       0.14      0.38      0.21        40\n",
      "reachinggood       0.17      0.04      0.07      1189\n",
      "randomrandom       0.79      0.79      0.79      3998\n",
      "\n",
      "    accuracy                           0.61      5455\n",
      "   macro avg       0.25      0.33      0.26      5455\n",
      "weighted avg       0.62      0.61      0.60      5455\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reza_voxelsafety_com/.cache/bazel/_bazel_reza_voxelsafety_com/d620f0b6d4b41da06538aa48e57dfab6/execroot/voxel/bazel-out/k8-fastbuild/bin/third_party/jupyter/jupyter.runfiles/pip_deps_scikit_learn/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004f26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import os.path\n",
    "import random\n",
    "import sys\n",
    "import xml.etree.ElementTree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.data\n",
    "import cv2\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd01b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
