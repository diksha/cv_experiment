{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f5a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import psycopg2\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef7d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"Username: \")\n",
    "password = input(\"Password: \")\n",
    "\n",
    "# Clear output\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    host=\"portal-production-postgres.c1trxszive18.us-west-2.rds.amazonaws.com\",\n",
    "    port=\"5432\",\n",
    "    database=\"portal_production_postgres\",\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71734b2b",
   "metadata": {},
   "source": [
    "# Z Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ProportionTestSample:\n",
    "    false_positive_rate: float\n",
    "    n: int\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ZTestResult:\n",
    "    p_value: float\n",
    "    z_score: float\n",
    "\n",
    "\n",
    "def two_tailed_test_z_score_to_p_value(z_score: float) -> float:\n",
    "    return scipy.stats.norm.sf(abs(z_score)) * 2\n",
    "\n",
    "\n",
    "def two_proportion_z_test(\n",
    "    observed_sample: ProportionTestSample, merged_sample: ProportionTestSample\n",
    "):\n",
    "    p1_hat = observed_sample.false_positive_rate\n",
    "    p2_hat = merged_sample.false_positive_rate\n",
    "\n",
    "    n1 = observed_sample.n\n",
    "    n2 = merged_sample.n\n",
    "\n",
    "    p_hat = (p1_hat * n1 + p2_hat * n2) / (n1 + n2)\n",
    "    z_score = (p1_hat - p2_hat) / sqrt(p_hat * (1 - p_hat) * (1 / n1 + 1 / n2))\n",
    "    return ZTestResult(\n",
    "        p_value=two_tailed_test_z_score_to_p_value(z_score), z_score=z_score\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b9c19",
   "metadata": {},
   "source": [
    "# Extracting Delorean Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, unique\n",
    "\n",
    "\n",
    "@unique\n",
    "class ReviewType(Enum):\n",
    "    DEFAULT_UNKNOWN = 0\n",
    "    TRUE_POSITIVE = 1\n",
    "    FALSE_POSITIVE = 2\n",
    "    UNSURE = 3\n",
    "\n",
    "\n",
    "def positive_negative_to_type(valid_count, invalid_count, unsure_count):\n",
    "    if valid_count > 0 and invalid_count == 0:\n",
    "        return ReviewType.TRUE_POSITIVE\n",
    "    if invalid_count > 0 and valid_count == 0:\n",
    "        return ReviewType.FALSE_POSITIVE\n",
    "    return ReviewType.UNSURE\n",
    "\n",
    "\n",
    "def get_additional_row_data(incidents_from_portal: pd.DataFrame):\n",
    "    \"\"\"Make track_uuid, sequence_id, and run_uuid accessible\"\"\"\n",
    "    incidents_from_portal[\"track_uuid\"] = incidents_from_portal.data.apply(\n",
    "        lambda data: data[\"track_uuid\"]\n",
    "    )\n",
    "    incidents_from_portal[\"sequence_id\"] = incidents_from_portal.data.apply(\n",
    "        lambda data: data.get(\"sequence_id\", \"None\")\n",
    "    )\n",
    "    incidents_from_portal[\"run_uuid\"] = incidents_from_portal.data.apply(\n",
    "        lambda data: data.get(\"run_uuid\", \"None\")\n",
    "    )\n",
    "    incidents_from_portal[\"incident_type\"] = incidents_from_portal.data.apply(\n",
    "        lambda data: data[\"incident_type_id\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a838de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delorean Incidents\n",
    "sql = (\n",
    "    \"SELECT * \"\n",
    "    \"FROM api_incident \"\n",
    "    \"WHERE data->>'cooldown_tag' = 'True' \"\n",
    "    \"AND data->>'track_uuid' is not null \"\n",
    "    \"AND \"\n",
    "    \"((data->>'incident_type_id' in \"\n",
    "    \"('PRODUCTION_LINE_DOWN', 'SPILL', 'OPEN_DOOR_DURATION', 'N_PERSON_PED_ZONE') \"\n",
    "    \"AND data->>'run_uuid' is not null) \"\n",
    "    \"OR data->>'incident_type_id' not in \"\n",
    "    \"('PRODUCTION_LINE_DOWN', 'SPILL', 'OPEN_DOOR_DURATION', 'N_PERSON_PED_ZONE')) \"\n",
    "    \"ORDER BY data->>'track_uuid', created_at\"\n",
    ")\n",
    "\n",
    "delorean_incidents = pd.read_sql(sql, conn)\n",
    "delorean_incidents[\"review_category\"] = delorean_incidents.apply(\n",
    "    lambda row: positive_negative_to_type(\n",
    "        row[\"valid_feedback_count\"],\n",
    "        row[\"invalid_feedback_count\"],\n",
    "        row[\"unsure_feedback_count\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "get_additional_row_data(delorean_incidents)\n",
    "print(f\"DELOREAN INCIDENTS SHAPE: {delorean_incidents.shape}\")\n",
    "\n",
    "# Head Incidents\n",
    "track_uuids = tuple(delorean_incidents.track_uuid.unique())\n",
    "\n",
    "sql = (\n",
    "    \"SELECT * \"\n",
    "    \"FROM api_incident \"\n",
    "    f\"WHERE data->>'track_uuid' in {track_uuids} \"\n",
    "    \"AND data->>'cooldown_tag' = 'False' \"\n",
    "    \"AND \"\n",
    "    \"((data->>'incident_type_id' in \"\n",
    "    \"('PRODUCTION_LINE_DOWN', 'SPILL', 'OPEN_DOOR_DURATION', 'N_PERSON_PED_ZONE') \"\n",
    "    \"AND data->>'run_uuid' is not null) \"\n",
    "    \"OR data->>'incident_type_id' not in \"\n",
    "    \"('PRODUCTION_LINE_DOWN', 'SPILL', 'OPEN_DOOR_DURATION', 'N_PERSON_PED_ZONE')) \"\n",
    "    \"ORDER BY data->>'track_uuid', created_at\"\n",
    ")\n",
    "head_incidents = pd.read_sql(sql, conn)\n",
    "head_incidents[\"review_category\"] = head_incidents.apply(\n",
    "    lambda row: positive_negative_to_type(\n",
    "        row[\"valid_feedback_count\"],\n",
    "        row[\"invalid_feedback_count\"],\n",
    "        row[\"unsure_feedback_count\"],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "get_additional_row_data(head_incidents)\n",
    "print(f\"PRIMARY INCIDENTS SHAPE: {head_incidents.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "incident_order = {\n",
    "    \"title\": [\n",
    "        \"BAD_POSTURE\",\n",
    "        \"DOOR_VIOLATION\",\n",
    "        \"HARD_HAT\",\n",
    "        \"NO_PED_ZONE\",\n",
    "        \"NO_STOP_AT_DOOR_INTERSECTION\",\n",
    "        \"NO_STOP_AT_END_OF_AISLE\",\n",
    "        \"NO_STOP_AT_INTERSECTION\",\n",
    "        \"N_PERSON_PED_ZONE\",\n",
    "        \"OPEN_DOOR_DURATION\",\n",
    "        \"OVERREACHING\",\n",
    "        \"PARKING_DURATION\",\n",
    "        \"PIGGYBACK\",\n",
    "        \"PRODUCTION_LINE_DOWN\",\n",
    "        \"SAFETY_VEST\",\n",
    "        \"SPILL\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "fig = px.histogram(\n",
    "    head_incidents,\n",
    "    x=\"title\",\n",
    "    color=\"title\",\n",
    "    barmode=\"group\",\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"title\": \"Incident Type\",\n",
    "    },\n",
    "    category_orders=incident_order,\n",
    "    title=\"Head Incidents\",\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig2 = px.histogram(\n",
    "    delorean_incidents,\n",
    "    x=\"title\",\n",
    "    color=\"title\",\n",
    "    barmode=\"group\",\n",
    "    height=400,\n",
    "    labels={\n",
    "        \"title\": \"Incident Type\",\n",
    "    },\n",
    "    category_orders=incident_order,\n",
    "    title=\"Delorean Incidents\",\n",
    ")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e6f0c",
   "metadata": {},
   "source": [
    "# Head Merging Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d87182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_merge_percentage(\n",
    "    first_incidents: pd.DataFrame, tail_incidents: pd.DataFrame\n",
    "):\n",
    "    incident_types = []\n",
    "    count_head_incidents = []\n",
    "    count_head_incidents_with_tail = []\n",
    "    count_tail_incidents = []\n",
    "    count_tp_head = []\n",
    "    count_fp_head = []\n",
    "    count_uk_head = []\n",
    "    tp_predictive_ratios = []\n",
    "    fp_predictive_ratios = []\n",
    "    uk_predictive_ratios = []\n",
    "    for incident_type in np.sort(first_incidents.incident_type.unique()):\n",
    "        # Get all incidents of type incident_type\n",
    "        typed_head_incidents = first_incidents[\n",
    "            first_incidents.incident_type == incident_type\n",
    "        ]\n",
    "        has_tail = []\n",
    "        typed_tail_incidents = tail_incidents[\n",
    "            tail_incidents.incident_type == incident_type\n",
    "        ]\n",
    "        count_no_tail = 0\n",
    "        count_tail_tp_given_head_tp = 0\n",
    "        count_tail_given_head_tp = 0\n",
    "        count_tail_fp_given_head_fp = 0\n",
    "        count_tail_given_head_fp = 0\n",
    "        count_tail_uk_given_head_uk = 0\n",
    "        count_tail_given_head_uk = 0\n",
    "        for _, head_incident in typed_head_incidents.iterrows():\n",
    "            track_uuid = head_incident.track_uuid\n",
    "            # Get groupings for static actor incidents\n",
    "            if incident_type in (\n",
    "                \"PRODUCTION_LINE_DOWN\",\n",
    "                \"SPILL\",\n",
    "                \"OPEN_DOOR_DURATION\",\n",
    "                \"N_PERSON_PED_ZONE\",\n",
    "            ):\n",
    "                run_uuid = head_incident.run_uuid\n",
    "                sequence_id = head_incident.sequence_id\n",
    "                subsequent_incidents = typed_tail_incidents[\n",
    "                    (typed_tail_incidents.track_uuid == track_uuid)\n",
    "                    & (typed_tail_incidents.run_uuid == run_uuid)\n",
    "                    & (typed_tail_incidents.sequence_id == sequence_id)\n",
    "                ]\n",
    "            # Get groupings for non static actor incidents\n",
    "            else:\n",
    "                subsequent_incidents = typed_tail_incidents[\n",
    "                    typed_tail_incidents.track_uuid == track_uuid\n",
    "                ]\n",
    "\n",
    "            if subsequent_incidents.empty:\n",
    "                count_no_tail += 1\n",
    "                has_tail.append(False)\n",
    "                continue\n",
    "\n",
    "            has_tail.append(True)\n",
    "            head_review_type = head_incident.review_category\n",
    "            tail_head_match = subsequent_incidents.review_category.eq(\n",
    "                head_review_type\n",
    "            )\n",
    "            if head_review_type == ReviewType.TRUE_POSITIVE:\n",
    "                count_tail_tp_given_head_tp += tail_head_match.sum()\n",
    "                count_tail_given_head_tp += tail_head_match.size\n",
    "            elif head_review_type == ReviewType.FALSE_POSITIVE:\n",
    "                count_tail_fp_given_head_fp += tail_head_match.sum()\n",
    "                count_tail_given_head_fp += tail_head_match.size\n",
    "            else:\n",
    "                count_tail_uk_given_head_uk += tail_head_match.sum()\n",
    "                count_tail_given_head_uk += tail_head_match.size\n",
    "\n",
    "        incident_types.append(incident_type)\n",
    "        count_head_incidents.append(typed_head_incidents.shape[0])\n",
    "        count_head_incidents_with_tail.append(\n",
    "            typed_head_incidents.shape[0] - count_no_tail\n",
    "        )\n",
    "        count_tp_head.append(\n",
    "            typed_head_incidents[has_tail]\n",
    "            .review_category.eq(ReviewType.TRUE_POSITIVE)\n",
    "            .sum()\n",
    "        )\n",
    "        count_fp_head.append(\n",
    "            typed_head_incidents[has_tail]\n",
    "            .review_category.eq(ReviewType.FALSE_POSITIVE)\n",
    "            .sum()\n",
    "        )\n",
    "        count_uk_head.append(\n",
    "            typed_head_incidents[has_tail]\n",
    "            .review_category.eq(ReviewType.UNSURE)\n",
    "            .sum()\n",
    "        )\n",
    "        count_tail_incidents.append(typed_tail_incidents.shape[0])\n",
    "        tp_predictive_ratios.append(\n",
    "            float(count_tail_tp_given_head_tp) / count_tail_given_head_tp\n",
    "            if count_tail_given_head_tp != 0\n",
    "            else None\n",
    "        )\n",
    "        fp_predictive_ratios.append(\n",
    "            float(count_tail_fp_given_head_fp) / count_tail_given_head_fp\n",
    "            if count_tail_given_head_fp != 0\n",
    "            else None\n",
    "        )\n",
    "        uk_predictive_ratios.append(\n",
    "            float(count_tail_uk_given_head_uk) / count_tail_given_head_uk\n",
    "            if count_tail_given_head_uk != 0\n",
    "            else None\n",
    "        )\n",
    "    incident_merge_percentage = {\n",
    "        \"incident_type\": incident_types,\n",
    "        \"count_head_incidents\": count_head_incidents,\n",
    "        \"count_head_incidents_with_tail\": count_head_incidents_with_tail,\n",
    "        \"count_tail_incidents\": count_tail_incidents,\n",
    "        \"count_tp_head\": count_tp_head,\n",
    "        \"count_fp_head\": count_fp_head,\n",
    "        \"count_uk_head\": count_uk_head,\n",
    "        \"tp_predictive_ratios\": tp_predictive_ratios,\n",
    "        \"fp_predictive_ratios\": fp_predictive_ratios,\n",
    "        \"uk_predictive_ratios\": uk_predictive_ratios,\n",
    "    }\n",
    "    return incident_merge_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ecb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(\n",
    "    calculate_merge_percentage(head_incidents, delorean_incidents)\n",
    ")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de78800f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
