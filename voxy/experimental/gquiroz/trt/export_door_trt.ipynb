{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dea306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "\n",
    "sys.path.append(os.environ[\"BUILD_WORKSPACE_DIRECTORY\"])\n",
    "from loguru import logger as LOGGER\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "import onnx\n",
    "import onnxsim\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = \"/home/gabriel/models/doors\"\n",
    "from lib.ml.inference.backends.trt import Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a33ecf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a17348",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_model_path = Path(\n",
    "    os.path.join(\n",
    "        MODEL_DIR,\n",
    "        \"2022-10-26_americold_modesto_0011_cha/2022-10-26_americold_modesto_0011_cha.pt\",\n",
    "    )\n",
    ")\n",
    "device = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "example_input = (\n",
    "    torch.randn(16, 3, 224, 224, requires_grad=False).to(device).half()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc56ab7",
   "metadata": {},
   "source": [
    "## Convert torchscript to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebcb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_path = ts_model_path.with_suffix('.onnx')\n",
    "extra_files = {\"model_config\": \"\"}\n",
    "ts_model = torch.jit.load(ts_model_path, _extra_files=extra_files).eval().half()\n",
    "example_output = ts_model(example_input)\n",
    "output_names = [\"output0\"]\n",
    "dynamic = {'images': {0: 'batch', 2: 'height', 3: 'width'}}  # shape(1,3,224,224)\n",
    "dynamic['output0'] = {0: 'batch', 1: 'anchors'}  # shape(1,25200,85)\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        ts_model,\n",
    "        example_input,\n",
    "        onnx_model_path,\n",
    "        verbose=False,\n",
    "        opset_version=12,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['images'],\n",
    "        output_names=[\"output0\"]\n",
    "        example_outputs=example_output,\n",
    "        dynamic_axes=dynamic,\n",
    "    )\n",
    "    onnx_model = onnx.load(onnx_model_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    onnx.save(onnx_model, onnx_model_path)\n",
    "    \n",
    "    onnx_model, check = onnxsim.simplify(onnx_model)\n",
    "    assert check, 'assert check failed'\n",
    "    onnx.save(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ef8eb",
   "metadata": {},
   "source": [
    "## Convert onnx to engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = 4\n",
    "engine_model_path = ts_model_path.with_suffix(\".engine\")\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "builder = trt.Builder(logger)\n",
    "config = builder.create_builder_config()\n",
    "config.max_workspace_size = workspace * 1 << 30\n",
    "flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "network = builder.create_network(flag)\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "if not parser.parse_from_file(str(onnx_model_path)):\n",
    "    raise RuntimeError(f\"failed to load ONNX file: {onnx_model_path}\")\n",
    "inputs = [network.get_input(i) for i in range(network.num_inputs)]\n",
    "outputs = [network.get_output(i) for i in range(network.num_outputs)]\n",
    "for inp in inputs:\n",
    "    LOGGER.info(\n",
    "        f'TensorRT input \"{inp.name}\" with shape{inp.shape} {inp.dtype}'\n",
    "    )\n",
    "for out in outputs:\n",
    "    LOGGER.info(\n",
    "        f'TensorRT output \"{out.name}\" with shape{out.shape} {out.dtype}'\n",
    "    )\n",
    "if example_input.shape[0] <= 1:\n",
    "    LOGGER.warning(\n",
    "        f\"TensorRT WARNING dynamic model requires maximum --batch-size argument\"\n",
    "    )\n",
    "profile = builder.create_optimization_profile()\n",
    "for inp in inputs:\n",
    "    profile.set_shape(\n",
    "        inp.name,\n",
    "        (1, *example_input.shape[1:]),\n",
    "        (max(1, example_input.shape[0] // 2), *example_input.shape[1:]),\n",
    "        example_input.shape,\n",
    "    )\n",
    "config.add_optimization_profile(profile)\n",
    "if builder.platform_has_fast_fp16:\n",
    "    config.set_flag(trt.BuilderFlag.FP16)\n",
    "with builder.build_engine(network, config) as engine, open(\n",
    "    engine_model_path, \"wb\"\n",
    ") as t:\n",
    "    t.write(engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Backend(engine_model_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb4a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c78f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
