models:
# Door State Configs
  - artifact_model_paths:
      - artifacts_01_09_2023_wn_foods_hayward_0009_cha/8380802c-969f-44a0-b909-72c83fa2bb66.pt
      - artifacts_01_09_2023_wn_foods_hayward_0012_cha/860ebac6-dc32-43ed-91dd-a6b61bc04dce.pt
      - artifacts_02_15_2023_wn_foods_hayward_0011_cha/9b4a0f9b-5c33-4af2-b6d1-238ee9b30232.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 224, 224]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [3]
# Human Keypoint Detection Configs
  - artifact_model_paths:
      - artifacts_03_21_2023_pose_0630_jit_update/fast_res50_256x192.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 128
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 256, 192]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [17, 64, 48]
# Carry object classifier
  - artifact_model_paths:
     -  artifacts_03_24_2023_carry_classifier_jit/best_lift_DSv4_RN34-jit.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 32
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 224, 224]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [2]
# Ergonomic Overreach Configs
  - artifact_model_paths:
      - artifacts_03_23_2023_overreaching_model_jit/voxel_ergo_ml_overreaching_2022-05-23-jit.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 128
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NONE
          dims: [30]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [2]
# Spill Config
  - artifact_model_paths:
      - artifacts_02_05_2023_spill_generalized_jit/smp-bd6b62dfd5b64dcfb4970102e2c9b2aa-jit.pt
    disable_warmup_generation: true
    config:
      platform: pytorch_libtorch
      max_batch_size: 128
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, -1, -1]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [1, -1, -1]
# Object Detection Configs
  - artifact_model_paths:
      - artifacts_yolo_v5_pre_processing_04_13_2023/yolo_torchscript_preprocess_apr_13.pt
    disable_warmup_generation: true
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: INPUT_0
          data_type: TYPE_UINT8
          format: FORMAT_NHWC
          dims: [-1, -1, 3]
        - name: INPUT_1
          data_type: TYPE_INT32
          dims: [2]
      output:
        - name: OUTPUT_0
          data_type: TYPE_FP16
          dims: [3, -1, -1]
        - name: OUTPUT_1
          data_type: TYPE_FP32
          dims: [2]
        - name: OUTPUT_2
          data_type: TYPE_FP32
          dims: [2]
  - artifact_model_paths:
      - artifacts_yolo_v5_post_processing_04_11_2023/yolo_torchscript_postprocess_apr_11.pt
    disable_warmup_generation: true
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: input0
          data_type: TYPE_FP16
          dims: [-1, -1]
        - name: input1
          data_type: TYPE_FP32
          dims: [2]
        - name: input2
          data_type: TYPE_FP32
          dims: [2]
        - name: input3
          data_type: TYPE_INT32
          dims: [2]
        - name: input4
          data_type: TYPE_FP16
          dims: [1]
        - name: input5
          data_type: TYPE_FP16
          dims: [1]
      output:
        - name: output0
          data_type: TYPE_INT64
          dims: [1]
        - name: output1
          data_type: TYPE_FP32
          dims: [-1]
  - artifact_model_paths:
      - artifacts_2022-11-15-03-38-16-91db-yolo/best_736_1280.engine
    disable_warmup_generation: true
    config:
      platform: tensorrt_plan
      max_batch_size: 2
      input:
        - name: images
          data_type: TYPE_FP16
          format: FORMAT_NCHW
          dims: [3, -1, -1]
      output:
        - name: output0
          data_type: TYPE_FP16
          dims: [-1, -1]
ensembles:
# Object Detection 2D Ensemble
  - primary_model_name: yolo_model
    artifact_model_paths:
      - artifacts_2022-11-15-03-38-16-91db-yolo/best_736_1280.engine
    config:
      platform: ensemble
      max_batch_size: 1
      input:
        - name: INPUT_0
          data_type: TYPE_UINT8
          format: FORMAT_NHWC
          dims: [-1, -1, 3]
        - name: INPUT_1
          data_type: TYPE_INT32
          dims: [2]
        - name: INPUT_2
          data_type: TYPE_INT32
          dims: [-1]
        - name: INPUT_3
          data_type: TYPE_FP16
          dims: [1]
        - name: INPUT_4
          data_type: TYPE_FP16
          dims: [1]
      output:
        - name: output0
          data_type: TYPE_INT64
          dims: [1]
        - name: output1
          data_type: TYPE_FP32
          dims: [9]
      ensemble_scheduling:
        step:
          - model_name: artifacts_yolo_v5_pre_processing_04_13_2023/yolo_torchscript_preprocess_apr_13.pt
            model_version: 1
            input_map:
              INPUT_0: INPUT_0
              INPUT_1: INPUT_1
            output_map:
              OUTPUT_0: images
              OUTPUT_1: offset
              OUTPUT_2: scale
          - model_name: yolo_model
            model_version: 1
            input_map:
              images: images
            output_map:
              output0: predictions
          - model_name: artifacts_yolo_v5_post_processing_04_11_2023/yolo_torchscript_postprocess_apr_11.pt
            model_version: 1
            input_map:
              input0: predictions
              input1: offset
              input2: scale
              input3: INPUT_2
              input4: INPUT_3
              input5: INPUT_4
            output_map:
              output0: output0
              output1: output1
