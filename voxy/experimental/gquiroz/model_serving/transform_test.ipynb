{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import pad, resize, InterpolationMode\n",
    "\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.environ[\"BUILD_WORKSPACE_DIRECTORY\"])\n",
    "from core.labeling.tools.pull_kinesis_feed import get_frame_from_kinesis\n",
    "from core.perception.detector_tracker.utils import (\n",
    "    letterbox,\n",
    ")\n",
    "from lib.ml.inference.tasks.object_detection_2d.yolov5.utils import (\n",
    "    preprocess_image,\n",
    ")\n",
    "from lib.ml.inference.tasks.object_detection_2d.yolov5.pre_processing_model import (\n",
    "    letterbox as letterbox_scripted,\n",
    "    preprocess_image as preprocess_image_scripted,\n",
    ")\n",
    "\n",
    "new_shape = (736, 1280)  # 720p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_uuid = \"americold/modesto/0011/cha\"\n",
    "time = (datetime.now() - timedelta(hours=2)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "input_image = get_frame_from_kinesis(camera_uuid, time)\n",
    "shape = input_image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f21942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs = 20\n",
    "ar = shape[1] / shape[0]\n",
    "original = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(input_image)\n",
    "plt.title(f\"Original Image: Shape, {shape}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9fda17",
   "metadata": {},
   "source": [
    "## Letterbox Resize Operation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28716a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letterbox Function\n",
    "r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "new_unpad = int(round(shape[0] * r)), int(round(shape[1] * r))\n",
    "\n",
    "# Legacy Letterbox Resize (Using cv2)\n",
    "legacy_resized_image = cv2.resize(\n",
    "    input_image,\n",
    "    (new_unpad[1], new_unpad[0]),  # cv2 expects width by height for resize\n",
    "    interpolation=cv2.INTER_LINEAR,\n",
    ")\n",
    "# New Letterbox Resize (Using torchvision)\n",
    "torchvision_resized_image = resize(\n",
    "    img=torch.from_numpy(input_image.transpose(2, 0, 1)).unsqueeze(0),\n",
    "    size=new_unpad,\n",
    "    interpolation=InterpolationMode.BILINEAR,\n",
    "    antialias=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = legacy_resized_image.shape\n",
    "ar = new_size[1] / new_size[0]\n",
    "f1 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(legacy_resized_image)\n",
    "plt.title(f\"CV2 Resize: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "new_size = torchvision_resized_image.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(torchvision_resized_image.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Torchvision Resize: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcccb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_torch_resized_image = torch.from_numpy(\n",
    "    legacy_resized_image.transpose(2, 0, 1)\n",
    ").unsqueeze(0)\n",
    "pixel_diff = legacy_torch_resized_image - torchvision_resized_image\n",
    "\n",
    "new_size = pixel_diff.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f3 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(pixel_diff.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Pixel Diff: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e45507",
   "metadata": {},
   "source": [
    "## Letterbox Border Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy Letterbox\n",
    "color = (114, 114, 114)\n",
    "dh, dw = (\n",
    "    new_shape[0] - new_unpad[0],\n",
    "    new_shape[1] - new_unpad[1],\n",
    ")\n",
    "dh /= 2\n",
    "dw /= 2\n",
    "top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "# Use legacy padded image for analysis\n",
    "legacy_padded_image = cv2.copyMakeBorder(\n",
    "    legacy_resized_image,\n",
    "    top,\n",
    "    bottom,\n",
    "    left,\n",
    "    right,\n",
    "    cv2.BORDER_CONSTANT,\n",
    "    value=color,\n",
    ")\n",
    "# Use torchvision padded image\n",
    "torchvision_padded_image = pad(\n",
    "    img=torch.from_numpy(legacy_resized_image.transpose(2, 0, 1)).unsqueeze(0),\n",
    "    padding=[left, top, right, bottom],\n",
    "    fill=114,\n",
    "    padding_mode=\"constant\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = legacy_padded_image.shape\n",
    "ar = new_size[1] / new_size[0]\n",
    "f1 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(legacy_padded_image)\n",
    "plt.title(f\"CV2 Pad: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "new_size = torchvision_padded_image.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(torchvision_padded_image.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Torchvision Pad: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeb6dd1",
   "metadata": {},
   "source": [
    "## Letterbox Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_letterbox = letterbox(\n",
    "    input_image, (736, 1280), auto=False\n",
    ")  # Legacy YOLO preprocessing\n",
    "scripted_letterbox = letterbox_scripted(\n",
    "    torch.from_numpy(input_image.transpose(2, 0, 1)).unsqueeze(0),\n",
    "    torch.tensor(new_shape).unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6a8d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "legacy_letterbox_image = legacy_letterbox[0]\n",
    "new_size = legacy_letterbox_image.shape\n",
    "ar = new_size[1] / new_size[0]\n",
    "f1 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(legacy_letterbox_image)\n",
    "plt.title(f\"Legacy Letterbox: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "scripted_letterbox_image = (\n",
    "    scripted_letterbox[0].numpy().squeeze().transpose(1, 2, 0)\n",
    ")\n",
    "new_size = scripted_letterbox_image.shape\n",
    "ar = new_size[1] / new_size[0]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(scripted_letterbox_image)\n",
    "plt.title(f\"Scripted Letterbox: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "letterbox_absdiff_image = np.abs(\n",
    "    legacy_letterbox_image - scripted_letterbox_image\n",
    ")\n",
    "new_size = letterbox_absdiff_image.shape\n",
    "ar = new_size[1] / new_size[0]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(letterbox_absdiff_image)\n",
    "plt.title(f\"Diff in Letterbox: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1facd672",
   "metadata": {},
   "source": [
    "## Preprocess Image Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7aaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_preprocessed = preprocess_image(\n",
    "    torch.from_numpy(input_image).unsqueeze(0),\n",
    "    new_shape,\n",
    "    torch.device(\"cpu\"),\n",
    ")\n",
    "scripted_preprocess = preprocess_image_scripted(\n",
    "    torch.from_numpy(input_image).unsqueeze(0).to(\"cpu\"),\n",
    "    torch.tensor(new_shape).unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee989321",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "legacy_preprocess_image = (legacy_preprocessed[0] * 255).to(torch.uint8)\n",
    "new_size = legacy_preprocess_image.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f1 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(legacy_preprocess_image.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Legacy Preprocess: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "scripted_preprocess_image = (scripted_preprocess[0] * 255).to(torch.uint8)\n",
    "new_size = scripted_preprocess_image.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(scripted_preprocess_image.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Scripted Preprocess: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "preprocess_absdiff_image = (\n",
    "    legacy_preprocess_image - scripted_preprocess_image\n",
    ").abs()\n",
    "new_size = preprocess_absdiff_image.shape\n",
    "ar = new_size[3] / new_size[2]\n",
    "f2 = plt.figure(figsize=(fs, fs * ar))\n",
    "plt.imshow(preprocess_absdiff_image.numpy().squeeze().transpose(1, 2, 0))\n",
    "plt.title(f\"Diff in Preprocess: Shape, {new_size}\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3c061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
