models:
# Door State Configs
  - artifact_model_paths:
      - artifacts_01_18_2023_generalized-front-door/3f11d513-b9bd-471e-862e-4d2474fc443c.pt
      - artifacts_02_06_2023_generalized_EXIT_Door_new/7547a635-1ae9-4b9a-b44a-4e8991269ead.pt
      - artifacts_03_04_2023_generalized_freezer_door/c89809bd-ddad-451b-8e5e-c1e7d3434b41.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 224, 224]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [3]
# Human Keypoint Detection Configs
  - artifact_model_paths:
      - artifacts_03_21_2023_pose_0630_jit_update/fast_res50_256x192.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 128
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 256, 192]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [17, 64, 48]
          dims: [2]
# Carry object classifier
  - artifact_model_paths:
     -  artifacts_03_24_2023_carry_classifier_jit/best_lift_DSv4_RN34-jit.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 32
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NCHW
          dims: [3, 224, 224]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [2]
# Ergonomic Overreach Configs
  - artifact_model_paths:
      - artifacts_03_23_2023_overreaching_model_jit/voxel_ergo_ml_overreaching_2022-05-23-jit.pt
    config:
      platform: pytorch_libtorch
      max_batch_size: 128
      input:
        - name: images
          data_type: TYPE_FP32
          format: FORMAT_NONE
          dims: [30]
      output:
        - name: output0
          data_type: TYPE_FP32
          dims: [2]
# Object Detection Configs
  - artifact_model_paths:
      - artifacts_yolo_v5_pre_processing_04_13_2023/yolo_torchscript_preprocess_apr_13.pt
    disable_warmup_generation: true
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: INPUT_0
          data_type: TYPE_UINT8
          format: FORMAT_NHWC
          dims: [-1, -1, 3]
        - name: INPUT_1
          data_type: TYPE_INT32
          dims: [2]
      output:
        - name: OUTPUT_0
          data_type: TYPE_FP16
          dims: [3, -1, -1]
        - name: OUTPUT_1
          data_type: TYPE_FP32
          dims: [2]
        - name: OUTPUT_2
          data_type: TYPE_FP32
          dims: [2]
  - artifact_model_paths:
      - artifacts_yolo_v5_post_processing_04_11_2023/yolo_torchscript_postprocess_apr_11.pt
    disable_warmup_generation: true
    config:
      platform: pytorch_libtorch
      max_batch_size: 16
      input:
        - name: input0
          data_type: TYPE_FP16
          dims: [-1, -1]
        - name: input1
          data_type: TYPE_FP32
          dims: [2]
        - name: input2
          data_type: TYPE_FP32
          dims: [2]
        - name: input3
          data_type: TYPE_INT32
          dims: [2]
        - name: input4
          data_type: TYPE_FP16
          dims: [1]
        - name: input5
          data_type: TYPE_FP16
          dims: [1]
      output:
        - name: output0
          data_type: TYPE_INT64
          dims: [1]
        - name: output1
          data_type: TYPE_FP32
          dims: [-1]
  - artifact_model_paths:
      - artifacts_02_27_2023_michaels_wesco_office_yolo/best_736_1280.engine
    disable_warmup_generation: true
    config:
      platform: tensorrt_plan
      max_batch_size: 2
      input:
        - name: images
          data_type: TYPE_FP16
          format: FORMAT_NCHW
          dims: [3, -1, -1]
      output:
        - name: output0
          data_type: TYPE_FP16
          dims: [-1, -1]
ensembles:
# Object Detection 2D Ensemble
  - primary_model_name: yolo_model
    artifact_model_paths:
      - artifacts_02_27_2023_michaels_wesco_office_yolo/best_736_1280.engine
    config:
      platform: ensemble
      max_batch_size: 1
      input:
        - name: INPUT_0
          data_type: TYPE_UINT8
          format: FORMAT_NHWC
          dims: [-1, -1, 3]
        - name: INPUT_1
          data_type: TYPE_INT32
          dims: [2]
        - name: INPUT_2
          data_type: TYPE_INT32
          dims: [-1]
        - name: INPUT_3
          data_type: TYPE_FP16
          dims: [1]
        - name: INPUT_4
          data_type: TYPE_FP16
          dims: [1]
      output:
        - name: output0
          data_type: TYPE_INT64
          dims: [1]
        - name: output1
          data_type: TYPE_FP32
          dims: [9]
      ensemble_scheduling:
        step:
          - model_name: artifacts_yolo_v5_pre_processing_04_13_2023/yolo_torchscript_preprocess_apr_13.pt
            model_version: 1
            input_map:
              INPUT_0: INPUT_0
              INPUT_1: INPUT_1
            output_map:
              OUTPUT_0: images
              OUTPUT_1: offset
              OUTPUT_2: scale
          - model_name: yolo_model
            model_version: 1
            input_map:
              images: images
            output_map:
              output0: predictions
          - model_name: artifacts_yolo_v5_post_processing_04_11_2023/yolo_torchscript_postprocess_apr_11.pt
            model_version: 1
            input_map:
              input0: predictions
              input1: offset
              input2: scale
              input3: INPUT_2
              input4: INPUT_3
              input5: INPUT_4
            output_map:
              output0: output0
              output1: output1
